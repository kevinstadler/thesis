\section{Why model?}

Within the field of language evolution (here meant to encompass both research on the evolution of the human language capacity, as well as `mere' modelling of the type of cultural, linguistic changes described above) computational models have undergone pronounced trends. % hype phase
During the hayday of computational modelling, the field produced first a plethora of quantitative, computational models of the evolution of the language faculty~\citep{Kirby1999,Nowak2001a} as well as the evolution of linguistic conventions, such as the `Naming Game'~\citep[see \citet{Wellens2012} for a review]{Baronchelli2008}. Around the same time, similar methodologies became popular to study the dynamics of language change in general~\citep{Niyogi1995,Niyogi1997,Livingstone2000,Wedel2006,Baxter2006,Wedel2007,Fagyal2010,Blythe2012,Gong2012,Pierrehumbert2014} as well as some specific historical changes in particular~\citep{Baxter2009,Sonderegger2010,Swarup2012,Kirby2013,Kirby2013cogsci}. % Vazquez-Larruscain2006 (nedergard-thomsen book), Ritt, Evolang people this year

% Bloomfield1933 on density, followed by Stanford2013

Given the relatively abrupt rise of this new methodology, it is not surprising that this hype was followed by several meta-scientific and review papers advocating and/or defending the use of computational models~\citep{DeBoer2006,Baker2008,Jaeger2009,Hruschka2009,Vogt2010,DeBoer2012EvoLang}. Since most parts of this thesis are going to be concerned with computational modelling, it is worth asking: what \emph{is} the point of having a computational model?

Summarising the thrust of the review papers above, a computational allows~(or rather forces) one to step away from pure arm-chair theorising about dynamical systems that consist of many interacting parts. Instead of guessing at the effects of micro-level assumptions on the macro-level dynamics of the system, a computational approach forces the researcher to explicitly lay out their assumptions about the individual, interacting parts in a quantitatively measurable (and ideally reproducible) way. From there, computational methods take the lead by determining in an objective way how the transparent assumptions about individual behaviour culminate in (potentially) complex interactional phenomena in the population.

Computational models thus allow us to both directly compare the expected macro-level behaviour of an interacting system under different micro-level assumptions, but also to explicitly test different parameter conditions of the same model to determine the respective influence of different biases or model parameters.

Partly in order to make computational models more appealing and convincing to the non-modeller, the gist of a lot of modelling papers is that models are not some sort of obfuscating black magic, but instead a tool for revelation and enlightenment.
In many cases, this sentiment runs the risk of trivialising either the models themselves, or at least the analyses presented~(the latter point will be made clear with an example in Section~\ref{sec:realigriffiths})

%(see e.g.~\citealt{Wellens2012}'s critique of Vogt+Cuymans)

Also, the promise that explicitly spelling out the quantitative assumptions of different models would bring clarity to the field is not as straightforward. Dependent on the precise framings of the same logical problem, e.g. the establishment of a shared communication system, superficially different mechanics which actually have very similar effects on a behavioural level have been in competition for years. Without a dedicated effort to replicate existing models and bring them in direct relation to each other, even computational models can run risk of becoming ideological `blackboxes', counter to their original intention to make assumptions more transparent~\citep[see][for the exemplary case of proposed pressures]{Spike2016}.

% TODO list the general modelling dynamics papers above and group them by replicator/interactor bias?

Especially when models are explicitly dedicated to comparing the effect of different parameter settings \emph{within} them, the general dynamics (such as the basic learning rules or other aspects like population turnover employed in virtually every social learning model) are often taken for granted. It is important to note that much of the dynamics are implicit in these basic assumptions themselves. 

The computational models which have stood the test of time are therefore those which are not one-offs, such as many of the early models which employed bespoke ad-hoc learning rules that are often not grounded in the general learning literature, but models which have undergone intense study and analysis from the ground up. For the case of the evolution of novel inventions, the Naming Game is a case in point~\citep{Baronchelli2008}. For the case of language \emph{change}, i.e. the `pointless' replacement of one established convention by another, probably the most extensive and well-explored model is the Utterance Selection Model~(USM) of language change, which forms the basis of most of the modelling work in this thesis.

%It is with these words of caution in mind that we dive into an in-depth analysis of the (very) basic dynamics of two models

\input{modelling/usm}

\input{modelling/realigriffiths}

\section{A conclusion on modelling}

%\subsection{Modelling other factors in the USM}

\section{Trend-amplification and momentum-based selection}

The literature summarised above in Chapter~\ref{ch:review} as well as the pressures investigated in this chapter cover the bulk of the established accounts and theories about language change.
The remainder of this thesis is dedicated to the exploration of a selection proessure and class of models that is still relatively novel to the field: that of trend-amplification, or \emph{momentum-based} selection.

%\citep{Labov2001,Gureckis2009}
