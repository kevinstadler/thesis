%What drives linguistic changes?
\section{Introduction}

While the degree to which the historical development of languages is inferred and used by language learners has long been of interest to sociolinguists~\citep{Labov1989}, empirically this question has only been tackled relatively recently as part of a general effort to study the acquisition of sociolinguistic knowledge by individuals~\citep{Labov2014}.
Of particular relevance to this thesis is the question of how specific linguistic variants and their relative usage levels can come to be associated with specific age groups.
The concept of `age vectors' captures the age-based stratification of variable usage, and the idea that individual language users possess knowledge of the age vectors of their community has been invoked as an explanation of how language changes are transmitted and increment across generations~\citep{Labov2001}.
The model presented in the previous chapter demonstrated how a similar mechanism, based on tracking changes to frequency distributions of discrete variants in \emph{real time}, can equally account for spontaneous directed transitions of change in a speech community.

While there is an increasing body of empirical evidence on individuals' knowledge of ongoing changes which I reviewed in Section~\ref{sec:agevector}, the experimental data presented there was limited to continuous phonetic changes. Although the fact that this sub-domain of language change still encompasses the largest part of sociolinguistic research might in part be attributed to the generativist sovereignty over morphosyntactic research which did not leave much space for an empiricist-variationist methodology, it is worth noting that the type of sociolinguistic variable (i.e.~whether different variants differ continuously or categorically) influences not just how the linguist might describe or represent variation, but also how that variation is acquired by individuals. %makes a difference, in particular when it comes to enquiring about the \emph{knowledge} about changes.

In particular, the type of variable impacts on the amount of information on inter-individual differences that can be extracted from individual realisations of a variable that is observed in an interaction. While continuous phonetic tokens are potentially very noisy and it might therefore help to have access to a speaker's full distribution of realisations to get a complete picture of their variable usage, given sufficient stratification of variable realisations along a continuous dimension even a single token can potentially contain enough information to place the speaker along a cline from `more outdated' to `more modern' in their variant usage.
Not only that, continuous variants allow speakers to sound `\emph{even more} novel' by extending the change along that cline and producing variants that `overshoot' even the most advanced novel variants, productions which can nevertheless be immediately understood as instantiations of the same innovation.
%\citep{Swarup2012}.
%figure out the age vector between them, in theory you only need as little as one token each from a younger and an older speaker which, given the relative frequency of phonetic variables, should be easy enough to get access to.

The same is not true in the case of categorical variants. Firstly, in order to learn about an individual speaker's variable usage,
%level of participation in a change
one truly need to learn about the overall distribution of realisations, i.e.~the relative frequencies with which the different variants are mixed by the speaker.
Except when different variants are strong social markers which are exclusively used by non-overlapping speaker groups, very little information can be extracted from individual productions. %realisations of a variable.
%which could theoretically be the case for really rapid changes where youngers speakers categorically use only variant that is still unattested in 
Instead, several realisations of a variable by one and the same speaker are necessary to make strong inferences about a speaker.
In combination with the fact that morphosyntactic variables can only be observed much less frequently than most phonetic and phonological ones, 
it is not obvious that people would be as good at acquiring or making inferences about categorical variables as they are for continuous ones, like the vowel realisations tested by~\citet{Drager2011}.

%one sample each you're quite likely to end up with both producing the same token, which is uninformative.

%And to come back to frequency, you also need to wait until you've collected 5+ samples of imperatives with an explicit subject before you can make strong inferences about your speaker, so

%One could argue that all our speakers are doing is learn a simple 'new variant = younger speaker, old variant = older speaker' mapping, but the difference in responses between the imperative and question variables shows that this is not the case: while the reported apparent time differences could be explained by such a simple associative mapping, the fact that the new imperative variant is reported to be used relatively less by *all* speaker groups shows that individuals actually know something about the relative usage of the variants within the individual!

%Beyond the domain of continuous phonetic change,
In one of the rare studies investigating age effects for categorical rather than continuous~(phonetic) traits, \citet{Walker2011} showed the influence of congruence between `word age' and `voice age' in facilitating lexical access: listeners of all ages exhibited a speed-up in processing words produced by a voice indicative of an age group, exactly when the word was more likely to be used by speakers of that age group. %, whether the item or referent were outdated.
Although this experiment speaks to the influence of perceived age directly, it does not involve a sociolinguistic variable, since the different stimuli belong to different semantic domains, rather than being different ways of `saying the same thing'.

%in particular with respect to how variants and usage levels 

%Most traditional accounts of language change are based on the assumption that linguistic divergence occurs during language acquisition, mostly based on language-internal factors that make learners `mislearn' or `reanalyse' their linguistic input, causing them end up with a different target language than that spoken by their caretakers~\citep[see e.g.][]{Salmons2013}. But quantitative research on infants and adolescents has painted a much more refined picture of the \emph{target} of child language acquisition~\citep{Labov2012}. Of particular relevance is the question of how individuals acquire sociolinguistic variation, and how this acquisition develops over time. Quantitative studies of the linguistic patterns of different pre-adolescent age cohorts has shown that, while children's usage patterns might mirror the idiosyncratic language use of their caretakers up until about age three or four, learners then exhibit a pronounced ``outward-orientation'': shedding most of the influence of their caretaker speech, learners instead turn not just towards their peers, but towards the usage patterns in the wider speech community as a whole~\citep{Labov2014}. % also Labov2001, ch.13

The goal of the present work is to extend the body of research on `age vectors', as they are perceived and used by the individual, to the domain of syntactic change. Since this an understudied area of research, we will also present a novel questionnaire methodology designed to help quantify people's explicit knowledge about ongoing language changes, in particular their impressions of the changes' direction.

\section{Quantifying the awareness of syntactic changes}

In this work we investigate the human capacity for tracking changes in syntactic variables by probing speakers' awareness of three instances of the loss of verb movement in the variety of Scots spoken in Shetland. Shetland is an island group approximately 200km North of Great Britain with around 23,000 inhabitants across 15~inhabited islands~\citep[see also Figure~\ref{fig:shetland}]{Shetland2014}. While Shetland forms part of the United Kingdom, it was only passed from Denmark to the Crown of Scotland in the late 1400s, and the islands' linguistic history is correspondingly diverse. Although virtually all toponyms on the island can be traced back to Viking origins, the Scots settlers who emigrated to the islands following the annexation to the Scottish Crown brought their own vernaculars with them which gradually replaced the local \emph{Norn} language, a form of Old Norse that however continued to be spoken on the isles until the 18th century~\citep{Knooihuizen2009}. Today, the primary native vernacular of Shetland can be characterised as a variety of Scots, which itself is a continuum of language varieties spoken throughout the Scottish Lowlands that has developed largely in parallel to (rather than being derived from) the more well known English varieties that spread from England to many other parts of the globe~\citep[p.15]{Millar2007}.

Due to its insular location, Shetland Scots has retained many linguistic features typical of Germanic languages that the varieties of English and Scots on the British mainland have long lost. Some examples which will be evident in the questionnaire examples below are the relatively rich verbal inflection, or the maintenance of a number distinction in the 2nd person pronoun \emph{du}~(cognate with Middle English \emph{thou}). The core feature under investigation in this study is also one of the historically conservative kind, namely the inversion of the verb position in several syntactic contexts, which occurs alongside the emergence of periphrastic \emph{do} (or `do-support').
While for most areas of England the change away from the historically original verb-initial constructions~\citep[see][for a more detailed analysis]{Jamieson2015} can be dated to the period from 1500-1700~\citep{Ellegard1953,Kroch1989do}, the homologous change in Shetland Scots has only been unfolding over the course of the 20th century~\citep{Jonas2002}. % Millar2007 p.76
The three related changes currently ongoing in Shetland which we investigate in the current work are as follows:

\begin{itemize}
\item verb positioning in imperatives, which is changing from a raised verb (surface realisation \texttt{VSO}) to Standard English \texttt{SVO} structure. An example in Shetland Scots would be ``Mak du dy ain denner!'' vs. ``Du mak dy ain denner!'', with the latter (incoming) variant akin to Standard English syntax, i.e.~`You~(sg.) make your~(sg.) own dinner!'

\item yes/no question syntax: change from a main verb-initial to a `periphrastic do' structure, e.g. from ``Kens du Sarah?'' to ``Does du ken Sarah?'', with `ken' being the Scots lexeme for `to know'.

\item wh question syntax: change from plain \texttt{WhVSO} with a fronted main verb to a `periphrastic do' structure, i.e. \texttt{Wh-`do'-SVO}. An example of the two constructions would be old ``Whit gae du him?'' to ``Whit did du gie him?'', with `gie'/`gae' the Scots equivalents of Standard English `give'/`gave'.
\end{itemize}

In all three cases, usage of the incoming variants is already common. The two question variables are more advanced, with younger speakers almost categorically using the incoming variants~(with the exception of a few lexically specific items, see \citealt{Jamieson2015}).
% see also a current assessment of acceptability in 
So while the changes are in a sense nearing completion, all members of the speech community are still exposed to both outgoing and incoming variants due to their being used frequently by older speakers.

\begin{figure}
% preliminary
%\newlength{\twosubht}
%\newsavebox{\twosubbox}
%\sbox\twosubbox{%
%  \resizebox{\dimexpr\textwidth}{!}{%
%    \includegraphics[height=3cm]{figure/shetlandcontext}%
%    \includegraphics[height=3cm]{figure/shetlandold}%
%  }%
%}
%\setlength{\twosubht}{\ht\twosubbox}
\centering
%\subcaptionbox{Shetland's location in the North Sea}{\includegraphics[height=\twosubht]{figure/shetlandcontext}}%
%\subcaptionbox{The islands of Shetland\label{fig:whalsay}}{\includegraphics[height=\twosubht]{figure/shetlandold}}%
\includegraphics[width=0.6\textwidth]{figure/shetland}
\caption[Shetland's location in the North Sea]{Shetland's location in the North Sea. \textcircled{c} OpenStreetMap contributors}
\label{fig:shetland}
\end{figure}

\subsection{Methodology}\label{sec:questionnaire}

To quantify people's explicit knowledge about ongoing language changes we adapted a self-evaluation method originally used to investigate the perception of phonetic changes by \citet{Labov1966} and \citet{Trudgill1972}, who asked speakers to report their relative usage of several phonetic variables. We refined the methodology, so that every sociolinguistic variable under investigation was covered by a one page questionnaire eliciting speakers' estimates of their own usage, as well as that of other social groups, alongside other (folk-)linguistic beliefs about the linguistic variants themselves\footnote{The complete materials of the paper-based questionnaire can be found in Appendix~\ref{app:questionnaire}.}. At the top of each questionnaire page, the two competing syntactic variants were introduced in the following way:

\begin{framed}
\begin{center}
You are probably familiar with these two ways of asking somebody to do something:\\
``\emph{Mak du dy ain denner!''\hspace{3cm}``Du mak dy ain denner!''}
\end{center}
\end{framed}

The order of the two variants was randomised between individuals, in the above example the outgoing variant is on the left, the incoming one (akin to Standard English ``You make your own dinner!'') on the right. The dialectal spelling of the example sentences is quasi-standardised on Shetland, and their mixing with the Standard English formulations of the questionnaire is not unusual. The actual questionnaire consisted of the following five questions~(referred to as \emph{Q1} through \emph{Q5} throughout the text) which were intended to probe different aspects of people's explicit knowledge about the changes in question:

% How much do you use either of these variants? \begin{likert}\begin{tabular}{ x x x x x } $\square$ & $\square$ & $\square$ & $\square$ & $\square$ \\ I use only `Mak~du..' & I use more `Mak~du..' & I use both equally & I use more `Du~mak..' & I use only `Du~mak..' \end{tabular}\end{likert}

\begin{description}
\item[Question 1:] ``How much do you use either of these variants?'' \hfill \\ This explicit question regarding speakers' own frequency of use could be answered on a 5-point scale, with the options labelled `I use only~(variant 1)', `I use mostly~(variant 1)', `I use both equally', `I use mostly~(variant 2)' and `I use only~(variant 2)', with the order of the two variants matching those of their initial presentation at the top of the page. % This information can be correlated with grammaticality judgments
\item[Question 2:] ``How much do you think are people around you using either of the variants?'' \hfill \\ This question could again be answered on a 5-point scale with options `People use only~(variant 1/2)/mostly~(variant 1/2)/both equally'. This question does not just provide information on speakers' perception of their average interlocutors' frequency of use, but the \emph{relative difference} between the answers to questions 1 and 2 can potentially provide information on whether speakers think of themselves as being `ahead' or `behind' the curve of a particular change relative to their speech community. % (but see results)
\item[Question 3:] ``Which of the two variants do you think is \emph{older}?'' \hfill \\ This (intentionally vague) question is intended to get at speakers' beliefs or connotations regarding the `age' of the competing variants, without drawing explicit attention to the fact that the variable is in fact changing. The three possible answers were `(variant~1) is older', `(variant~2) is older' and `People have always used both', with the order of the two variants randomised.
\item[Questions 4+5:] ``How much do you think \emph{younger/older speakers} use either of the variants?'' \hfill \\ The final two questions tap into speakers' awareness of the apparent time development of a change, with the same 5-point options as above: `Younger/older speakers use only~(variant 1/2)/mostly~(variant 1/2)/both equally'. The order of the two questions was randomised between individuals.
\end{description}

Data collection proceeded in three stages: first, to pilot the methodology, 8~participants were asked to complete the paper version of the questionnaire on site in Shetland in January 2015. The pilot questionnaire consisted of just two sociolinguistic variables with the following example sentences:

\begin{enumerate}
\item verb positioning in imperatives: \emph{Mak du dy ain denner!} vs. \emph{Du mak dy ain denner!}, with the latter (incoming) variant akin to Standard English syntax, i.e.~`You~(sg.) make your~(sg.) own dinner!'
\item negation marking: \emph{He didna go} vs. \emph{He didnoo go} -- this sociolinguistic variable is not undergoing change and was added as a control, with `didna' being the negation variant used categorically in most of Shetland, set against the `didnoo' variant which is categorical only on the island of Whalsay to the East of Shetland's main island. With a population of around 1,000 and close links to the mainland, we expected the local `didnoo' variant (as well as its geographical patterning) to be known to all Shetland locals, an assumption that was borne out by several explicit references to the the variants' distribution by locals during data collection. %, this variable is related to the negation via \emph{na} vs. \emph{no} in mainland Scots).
\end{enumerate}

Following the successful pilot, 16 more participants were asked to complete an extended 4-page version of the questionnaire which covered two further variables:

\begin{enumerate}
\setcounter{enumi}{2}
\item yes/no question syntax: \emph{Kens du Sarah?} vs. \emph{Does du ken Sarah?}, i.e. ``Do you~(sg.) know Sarah?'', with `ken' being the Scots lexeme for `to know'
\item wh question syntax: \emph{Whit gae du him?} vs. \emph{Whit did du gie him?}, the latter again akin to Modern English syntax but with the Scots lexical items for Standard English `what' and `give'.
\end{enumerate}

These first 24 participants were part of a balanced sample matched for binary gender, age, and geographic location within Shetland. All participants grew up in and were currently living in rural locations in Shetland~(i.e.~outside the island's main town, Lerwick). Participants had on average spent 3.7 years living away from Shetland, typically for higher education, work or training purposes. In all cases, the questionnaire was administered as an exit-questionnaire following a $\approx40$~minute task which involved providing grammaticality judgments for a large number of examples of the changing variables in question as well as fillers, which was carried out in pairs~(see~\citealt{Jamieson2015} for a full description of the methodology and analysis of results). % with the researcher being a Shetland local

Finally, we created an identical online version of the 4-variable questionnaire which was advertised via email and social networks. The online questionnaire was self-contained (i.e.~not preceded by the grammaticality judgment task) and provided us with a convenience sample of another 53 participants from all over Shetland, who completed the questionnaire in April 2015\footnote{The online version of the questionnaire is still available for reference at \url{http://spellout.net/ibexexps/kstadler/shetland/experiment.html}.}.
%Apart from their age, gender and current geographical location we also collected information on all participants' occupation, where in Shetland they grew up, any extended times they spent outside the isles, as well as the origin of their parents.

\subsection{Hypotheses \& predictions}\label{sec:questionnairepredictions}

Based on previous research on both the specific syntactic changes under investigation as well as sociolinguistic knowledge more generally, we can derive several predictions about what effects we might expect so see \emph{a priori}.

Regarding differences between the sociolinguistic variables, prior work on verb inversion in Shetland as well as the results derived from the acceptability judgments reported in \citet{Jamieson2015} suggests that the two question variables should pattern differently from the imperatives. The change in question syntax is more advanced, with younger speaker using the incoming question variants almost exclusively. Across the population, we would therefore expect generally higher incoming variant usage for those two variables, as opposed to still relatively mixed usage of the two imperative variants. This general pattern should be observable to different degrees across all of our questions related to usage rates, i.e.~all questions but Q3.

If our informants are indeed aware of the ongoing changes and their directionality, this should be evident in their responses to questions 3 through~5. Here, all three changing variables under investigation should pattern differently from the stable negation variable which acts as our control: since this variable is not undergoing change, it provides us with a baseline for responses to explicit questions about variant age when variable usage is really patterned geographically rather than temporally. % (as far as we can tell none of the studies of sociophonetic knowledge about age reported results from non-changing baseline phonemic distinctions)

In terms of between-participant differences, we can test a number of hypotheses that are implicit in much contemporary sociolinguistic research: because many studies of sound changes in progress have found there to be a significant effect of gender (typically with females leading a change), it has been argued that, primarily due to their position in Western societies, women might be more sensitive to linguistic cues~(\citealt{Trudgill1972}, but see~\citealt{Eckert1989,Labov1990}). While the studies of automatic implicit sociophonetic knowledge discussed above have not revealed any effect of gender, \citet{Carrera-Sabate2014} showed that % based on explicit elicitation
young females were more explicitly aware of an ongoing sound change in the Lleidat√† dialect of Catalan. Although no gender differences have been reported for the current syntactic changes in Shetland, neither in production nor in terms of grammatical acceptability~\citep{Jamieson2015}, we can still assess the claim that female speakers might be more sensitive or aware of ongoing changes.

Another interesting question regarding between-speaker differences pertains to how the sociolinguistic knowledge of age patterning might differ between participants of different ages. For example, in her experiment \citet{Drager2011} found an effect of listener \emph{age}, where only \emph{older} participants' perception of vowels that were currently undergoing a chain shift were affected by the perceived age of the speaker whose tokens they were asked to classify. In other words, older speakers were actively compensating more strongly for the manipulated age difference, with younger speakers exhibiting less sociophonetic sensitivity, at least in the sense that they were not actively employing their knowledge of ongoing changes in the classification task. Although we should consider the possibility that the age of our participants will affect their sociolinguistic knowledge of the variables under investigation in this work, it is not possible to derive a straightforward prediction regarding the presence or direction of an effect from the literature. While age effects are also attested in the large body of empirical research on language \emph{attitudes}~\citep{Giles2004}, it is not immediately obvious how and whether the \emph{qualitative} evaluation of innovations (often assumed to be primarily negative, see e.g.~\citealt{Labov2001,Tagliamonte2012}) corresponds to the \emph{quantitative} evaluation and perception of changes, with currently no conclusive results regarding the effect of age on the latter. % We will return to the question of research methodology below.

\section{Results}

Pooling together the data from the paper-based and online questionnaires, the total number of responses was~$N=77$ for the imperative~(\texttt{imp}) and negation~(\texttt{neg}) variables, and~$N=69$ for the yes/no question~(\texttt{ynq}) as well as wh question~(\texttt{whq}) syntax. Both the locally collected and online samples had a similar age distribution, with participants ranging from \Sexpr{min(participants$age)} to \Sexpr{max(participants$age)} years, with a median age of \Sexpr{median(participants$age)}.

%\Sexpr{round(mean(subset(participants, condition=="online")$age))}/\Sexpr{round(mean(subset(participants, condition=="paper")$age))}, median age \Sexpr{median(subset(participants, condition=="online")$age)}/\Sexpr{r median(subset(participants, condition=="paper")$age)}

<<setup, echo=FALSE>>=
source("../knitr-setup.R")
source("shetland-data.R")
source("~/notes/orm.R")
@

<<questionnairelocation, fig.width=smallwidth, fig.height=smallwidth, fig.scap="Origin of questionnaire participants within Shetland, by condition", fig.cap="Origin of questionnaire participants within Shetland, by condition~(online convenience sample vs. paper-based controlled sample)">>=
counts <- table(participants$loc, participants$condition)[length(levels(participants$loc)):1,]
barplot(counts, col=rainbow(nrow(counts)), ylab="number of participants", xlim=c(0,4), legend.text=TRUE, args.legend=list(x="right", fill=rev(rainbow(nrow(counts)))), mar=c(0,0,0,0)) # xlab="condition"
@

In terms of the geographical location of our participants there was a bigger difference between the two samples, as can be seen in Figure~\ref{fig:questionnairelocation}. The balanced sample explicitly excluded speakers originally from Shetland's capital Lerwick, home to 7,500 of the islands' total population of 23,000. The Scots vernacular of Lerwick is undergoing a more rapid change towards Standard Scottish English~(SSE) forms than rural variants~\citep{Sundkvist2011}, a development that can be attributed to the larger influx of speakers of other English varieties due to the capital's role as a hub for offshore oil drilling in the surrounding sea.
% For example, the outgoing verb-initial constructions for questions are not attested even in older speakers from Lerwick~(Durham, p.c.).
The convenience sample on the other hand naturally includes a large proportion of Lerwick respondents. However, when it comes to their questionnaire responses, we did not find the Lerwick participants to pattern differently from the rest of the population for any of the questions.
%Even though we collected some information on the socio-economic status of our participants (in particular their profession), this data is of a qualitative nature and will therefore not be used in our statistical models.
%We will go through the results question by question.

Also, despite the fact that we might have expected the on-site participants to be more aware or sensitive to the questionnaire based on the preceding 40~minute acceptability judgment task on related syntactic variables, the type of data collection (paper-based on site vs. online) did not come out as a significant predictor in any of the statistical models reported below.

% TODO correlation between per-individual responses to the three variables?

\subsection{Assessing the reliability of subjective usage judgments}\label{sec:judgmentcorrelation}

Before we turn to the actual data analysis, we have to address a central issue of our methodology, namely the type of data collected and its reliability. While questionnaires are still one of the standard tools employed in dialectological research, explicit questions about language use have fallen into disfavour in the quantitative sociolinguistic tradition. One reason for this is that lay-people's subjective evaluation of linguistic forms is traditionally not regarded as a reliable indicator of usage, as overt evaluations are often assumed to reflect the participants' qualitative sociolinguistic attitudes rather than people's actual quantitative usage~(Labov, Trudgill, inter alia).
%With the topic of language attitudes established as a research area in its own right, in combination with
In combination with the increased availability of speech and text data analysis technology over the past few decades, the relevance of subjective data on language use outside dedicated areas of research such as language attitudes has all but disappeared.
There has, however, been a recent re-increase in interest in the beliefs that non-linguists have about language variation which bridges the two fields, with its own research methodologies often referred to as \emph{perceptual dialectology}~\citep{Montgomery2011}. % to which the current work can also be attributed.
Rather than completely discarding the opinions of laypersons on the topic of language, this approach raises a number of own research questions regarding how naive speakers' `folk beliefs' about language are related to language use as studied by linguists.

It is in this domain that broadly sociolinguistic approaches come closer to the methodologies still most frequently used to study syntax and syntactic variation, in particular by means of \emph{grammaticality judgments} which have over the years been replaced by more gradual \emph{acceptability judgments} provided by naive native speakers rather than linguistic researchers themselves~\citep{Cornips2005}.
% http://web.stanford.edu/group/cslipublications/cslipublications/HPSG/2013/miller.pdf
Based on this continuum of related research methods based on explicit linguistic opinions expressed by speakers, there is also an increasing amount of literature on the question of actual usage is reflected in acceptability judgments and processing preferences~\citep{Sorace2005,Featherston2005} as well as attitudinal data~\citep[see e.g.][]{Maegaard2013,Durham2014}.
In order to better understand the nature of the estimated usage levels obtained through our present methodology it is therefore insightful to cross-validate the results with other measures.
% here are some pointers I got off Jim Donaldson that one could possibly go into: Miller, Arregui et al. 2006 (The Recycling Hypothesis), Gibson and Thomas 1999 (perceiving ungrammatical sentences as grammatical), Hofmeister et al. 2014 Processing effects in linguistic judgment data, Keller 2001 Gradience in grammar, Manning 2003 Probabilistic syntax, Sorace and Keller 2005 Gradience in linguistic data)
%One concern is thus that the estimated usage rates reported, particularly those concerning the speakers' \emph{own} usage, might not be representative.
% TODO general sociolinguistic focus on phonetics/data critique?
%really the question of reliability is not the only reason for the abandonment of questionnaires, it coincided nicely with a focus on high-frequency phonetic variables and the increasing availability of recording devices
%One obvious concern regarding our methodology, which draws the participants' explicit attention to the changing variables in question, is how indicative the responses are of speakers' actual usage.
While we have no quantitative production data available for the three changing syntactic variables in question which are all very low in frequency,
we can, however, compare the relative usage rates against the grammatical acceptability judgments which were collected independently for the 24~participants during the first, on site phase of data collection~(see~\citealt{Jamieson2015}). %reported by the same participants.
If the novel methodology presented here is indeed reliable, we should expect good correlation between the two measures.

Despite the fact that both grammaticality judgments and usage rate estimates were gathered through explicit elicitation, there are two big differences between the two types of data: firstly, the usage rate estimates draw explicit attention to the type of speaker that it is envisaged to be representative of, i.e.~the speaker themselves, the `average' interlocutor in their community, or a `younger' or `older' speaker specifically. This framing focusses explicitly on the variants' use in a specific context, while the acceptability judgment draws the informants' attention primarily to the linguistic variant itself.
In this way, a quantitative acceptability judgment does not distinguish in a principled manner between utterances that the informant would use in their own production, and what they would accept (or expect) from some of their interlocutors, but never actually produce themselves.

The second difference is that the usage rates as collected here capture the \emph{relative} usage of the two competing variants of a sociolinguistic variable by directly contrasting the two equivalent forms of a single example sentence. The acceptability judgments on the other hand express the \emph{absolute} acceptability of an individual example sentence on a 7-point Likert scale, without speaking directly to the \emph{relative} usage of the two competing variants.

In order to assess the reliability of our usage estimates by correlating it with the acceptability judgment data, we first need to transform the two measures to comparable scales, keeping in mind those differences. The basic idea here is to convert the absolute judgments per variant into relative ratings per variable, by comparing the per-variant ratings of the incoming and outgoing realisations of the same example sentences. Transforming the acceptability judgments to relative scores can be done in several different ways and boils down to three decisions. While none of the choices turned out to have a strong effect on the results, it is worth discussing them to get an idea of how a methodology based around acceptability judgments can be related to the present questionnaire methodology.

The first question regards exactly \emph{which} acceptability judgments should be correlated with the usage estimates. The acceptability judgment data collected by~\citet{Jamieson2015} is more abundant: each of the 24~informants provided judgments for a total of 49~example sentences across the three changing variables, covering 17~different verb types, and some of the verbs were chosen because they are known to exhibit strong lexical effects that affect the choice of syntactic construction. The two principled ways to limit the lexical effects on the acceptability measures are, on one hand, to only correlate the judgments for those sentences where the verbs match those used in the respective example sentences from the questionnaire or, alternatively, to wash out lexical effects by taking the average acceptability score over all verbs used in the acceptability judgment task. Both approaches turn out to result in almost identical correlation coefficients, and even the inclusion of all individual lexical items leads to a highly significant (if~lower) correlation coefficient.

The second decision relates to how the two acceptability judgments for the two competing variants should be converted into one measure capturing their relative acceptability, akin to the direct juxtaposition of the ``which variant do you use more'' measure employed by the questionnaire. The two most straightforward ways to combine them into one measure is by taking the difference between the ratings for the incoming and the outgoing variant, either by subtraction (absolute difference in acceptability) or division (relative difference in acceptability). %\footnote{While division is in principle not a legal operation for ordinal responses, acceptability judgments collected on a Likert scale are frequently treated as numeric responses, and subjected to parametric statistical tests, see e.g.~\citet{TODO}.}.
Both approaches produce a numeric scale with a neutral centre point occupied by pairs of judgements where the incoming and outgoing variants were rated to be equally acceptable~($0$ for the absolute difference by subtraction, and $1$ for the relative difference by division). In terms of the relative ranking of pairs with differing judgments the two scales only differ marginally, as can be seen in Figure~\ref{fig:judgments} below, where it is relatively easy to identify the matching pairs of datapoints between the two graphs based on their y-axis position.\footnote{The main difference between the two different ways to convert the acceptability judgments concerns the resolution of the resulting scale: pairwise subtraction of the 7 possible ranks of the ordinal acceptability judgments yields a total of~\Sexpr{length(unique(as.vector(outer(1:7, 1:7, "-"))))} possible relative ratings, while the division method results in up to~\Sexpr{length(unique(as.vector(outer(1:7, 1:7, "/"))))} theoretically possible values, and consequently fewer ties. The impact of choosing either of the two approaches on the resulting correlation coefficients is still only marginal, and our results are not highly sensitive to either choice, as can be seen below.} %The coefficients derived from both calculations are reported in the results below.

Having transformed the absolute acceptability judgments to a relative acceptability scale, there is still a third decision to be made, namely which of the usage estimate ratings it should be correlated with. The separate questions in the questionnaire gathered data regarding different speaker groups, including the informants themselves as well as several idealised interlocutor groups. Intuitively, we would expect people's acceptability judgments to reflect their own probability of producing the respective variants, and it is indeed only their self-usage estimates that yield a significant correlation with the derived relative acceptability scores.

The relationship between the reported relative self-usage rates and both the absolute and relative difference in acceptability reported by the 24~participants in the paper condition are shown in Figure~\ref{fig:judgments}. Due to the large number of ties along the 5-point ordinal scale of the questionnaire we chose Kendall's $\tau_B$ to calculate the correlation between the two measures. We found the strongest correlation between informants' self-usage estimates and the relative difference of their acceptability judgments by division, with $\tau_B=\Sexpr{dx <- merge(meanmatchedjudgments, da); pvrank::rankor(as.numeric(dx[["self"]]), dx[["reldiff"]], "kendall", print=FALSE, type="greater")$Value}$. This correlation is significant at $p<.01$, as determined using the \texttt{pvrank} R package which provides p-value calculation for rank order correlation tests accounting for ties~\citep{pvrank1.1}. % TODO could also do clme(self ~ judgment, random=id, data=da) ??

<<judgments, fig.cap="Correlation between the 24 informants' reported self-usage rate of the two variants for the three changing variables~(x-axis, jittered) and the relative acceptability derived from the average acceptability judgments (y-axis), for two ways of calculating the relative preference of the variants: (a)~\\emph{absolute} difference in acceptability, calculated by subtracting the rating of the outgoing variant from the incoming one (b)~\\emph{relative} difference of the incoming vs. outgoing ratings, calculated by division. The mid-points of the two relative acceptability scales~(where two competing variants are judged as equally acceptable) are indicated by dashed lines.">>=
tightmargin(mfrow=c(1, 2), pty="s")
plotjudgmentcor(meanmatchedjudgments, "self", "absdiff", render="jitteredself", xlab="(a)")
plotjudgmentcor(meanmatchedjudgments, "self", "reldiff", render="jitteredself", xlab="(b)")
#plotjudgmentcor(meanmatchedjudgments, "other", "absdiff")
#plotjudgmentcor(meanmatchedjudgments, "other", "reldiff")
@

%(TODO could delve into comparing the two data types a bit more here, e.g. by looking at the marginal distributions of the acceptability vs. usage estimate data and see how the difference between them might capture facts about how far the change has already progressed?)

%The distribution of the relative acceptability judgments (plotted along the y-axis) is insightful: for the more advanced changes to the two question variables all but one variant pairing yielded a higher acceptability of the incoming question syntax, as can be seen from their placement above the central `equal acceptability' line.

%Those participants who found the incoming variants more acceptable also rated themselves as using them more often.

Having established that the subjective responses that make up our data set pattern closely with an independent measure of use in the form of acceptability judgments,
%do not merely reflect their sociolinguistic attitudes 
% speakers' actual usage, at least as far as we can derive from their
we can now turn to analysing our participants' responses, and the patterns found therein.

\subsection{Self-estimates of own usage}
\label{sec:selfresponses}

The first measure elicited from our participants was an estimate of their own usage levels for each of the linguistic variables in question.
The overall data, split by sociolinguistic variable and informant age, is shown in Figure~\ref{fig:selfresponses}. The first impression is that the response distribution is highly uneven, with the majority of responses falling onto the three categories of our 5-point-scale that indicate at least 50\% usage of the incoming variants.\footnote{Since the control variable exhibits stable variation, there is no `incoming' or `outgoing' variant in this sense. Instead, we have coded the more frequently used (i.e. geographically more widespread) variant as the `incoming' one.}

<<selfresponses, fig.cap="Distribution of informant age per reported level of own usage for the three changing variables as well as the stable, geographically conditioned control. The five response levels correspond to the five possible responses described in Section~\\ref{sec:questionnaire}, ranging from the leftmost `I only use the incoming variant' to `I only use the outgoing variant' at the very right.">>=

# previously: a single boxplot over the three changing variables, with superimposed scatterplot
#b <- boxplot(age~self, data=changing, plot=0)
#boxplot(age~self, data=changing, xlab="self-reported variant usage for the three changing variables", ylab="participant age (years)", names=paste(b$names, " (n=", b$n, ")", sep=""))
#points(jitter(as.numeric(changing$self)), changing$age, pch=20, col=changingcolors[changing$var])
#legend("topleft", legend=levels(changing$var), horiz=T, fill=changingcolors)

# 4 scatterplots - manually change factor order so the plot arrangement makes sense
#lattice::xyplot(d$age ~ d$self | factor(d$var, levels=c("imp", "whq", "neg", "ynq")))#, col=varcolors[d$var])

# 4 scatterplots superimposed on boxplots - maximum information transparency
fourboxplots <- function(formula) {
  par(mfcol=c(2, 2))
  for (v in vars) {
    dx <- variable(v)
    b <- boxplot(formula, data=dx, plot=0)
    boxplot(formula, data=dx, main=vardesc[[v]], ylab="participant age (years)", names=paste(b$names, "\n(n=", b$n, ")", sep=""), las=2)# col=temp.colors(5))
    # axis(1, at=1:length(labels), labels=levels(), srt=45)
    points(jitter(as.numeric(dx[[labels(terms(formula))]])), dx$age, col=varcolors[dx$var])
  }
}

fourboxplots(age ~ self)
# lattice::bwplot(age ~ self | var, data=d)

# 4 boxplots next to each other
#b <- boxplot(age~self+var, data=d, plot=0)
#boxplot(age~self+var, data=d, xlab="self-reported variant usage for the three changing variables", ylab="participant age (years)", names=paste(b$names, " (n=", b$n, ")", sep=""))

# add condition information (who knows what that was...)
#boxplot(age~self+condition, data=changing, xlab="self-reported variant usage for the three changing variables", ylab="participant age (years)", names=paste(b$names, " (n=", b$n, ")", sep=""))
#points(jitter(5*(as.numeric(changing$condition)-1)+as.numeric(changing$self)), changing$age, pch=20)


nullmdl <- clme(self ~ 1, random=id)
#agemdl <- clme(self ~ age, random=id)
varmdl <- clme(self ~ var, random=id)
varagemdl <- clme(self ~ age + var, random=id)
vargendermdl <- clme(self ~ gender + var, random=id)
vargenderagemdl <- clme(self ~ age + gender + var, random=id)
suppressWarnings(vargenderchangingmdl <- clme(self ~ gender*stable + var, random=id))
# age-gender interaction is near significance
#agegendermdl <- clme(self ~ age*gender, random=id)
#agechangingmdl <- clme(self ~ age*stable, random=id)
@

<<rankdeficientmodels, warning=FALSE, cache=FALSE>>=
# these ones are rank deficient
agevarchangingmdl <- clme(self ~ age*stable + var, random=id)
# this one is equivalent (Helmert coding) needed for the prediction
helmertagevarchangingmdl <- clme(self ~ age*notchanging + question + whq, random=id)

# age and gender effects appear to be orthogonal/cumulative
agegenderchangingvarmdl  <- clme(self ~ age*stable + gender + var, random=id)
# n.s.
#agegenderchangingvarmdl2  <- clme(self ~ var + age*stable + gender*stable, random=id)
fullmdl <- clme(self ~ age*var+gender, random=id)

# clmm2 confint() doesn't work for anything but stdev at the moment...
#fixedmodel <- clm(self ~ age*stable+var, data=d)
#fixedmodel <- clm(self ~ age*notchanging + question + whq, data=d)
#confint(fixedmodel)

# gender result does not translate to a gender difference in the perceived 'self/community-difference'
#rms::orm(selfdiff ~ gender, data=changing)
#rms::lrm(oldervar ~ gender, data=changing)
#rms::orm(apparentdiff ~ gender, data=changing)
@

As expected, the self-reports on the stable negation variable are patterned by the informants' geographical location, with the only four informants indicating categorical usage of the more localised variant all originating from the isle of Whalsay. In contrast, responses for the three changing variables appear to reflect differences in usage patterns in \emph{apparent time}, the familiar phenomenon where the language use of younger speakers is found to be more \emph{advanced}, i.e.~they exhibit higher usage rates of the new, incoming variants~\citep{Wagner2012theory}.
%In other words, if speakers are reporting their own usage accurately, we should expect individual responses to be predicted by the speakers' age, with younger speakers reporting higher usage levels of the incoming variants. The distribution of ages per response suggests that there might be such an effect:
While the mean age of respondents tends to decrease for higher reported usage of the incoming variants for the three changing variables, the same is not true for the stable control variable.
% For the three changing variables, however, the mean age of the respondents tends to decrease for responses reporting higher levels of the incoming variant.

% in unit age on the outcome distribution.
%This first result captures the fact that the change in verb position in imperatives is indeed lagging behind the two question variables.

%This conclusion receives independent support from the grammaticality judgments elicited from the first 24~participants, which exhibited high acceptability for both imperative variants, in contrast to comparatively lower acceptability ratings for the outgoing question forms\footnote{For an extended discussion of how the usage rate estimates correlate to acceptability judgments, see section~\ref{sec:judgmentcorrelation}.}.
% FIXME gotta select proper subset of judgment stimuli that matches the awareness questionnaires in terms of verb arity etc.?

To test our hypotheses we used ordered logistic regression, an extension of logistic regression that allows for more than two (ordered) response categories. We fit a number of models of increasing complexity using R's \texttt{ordinal} package~\citep{ordinal2015}, with participant as a random effect. %\footnote{Linear mixed effects regression models with the response variable coded as numeric rather than ordinal yields the same picture.}
% TODO and we performed model comparison using log-likelihood tests~\citep{Barr2013}.
The results from these models are shown in Table~\ref{table:selfresponsesmodelordinal}: the four coefficients at the very bottom of the table, present for all models, are equivalent to the \emph{intercept} in (generalised) linear models, only that ordinal regression requires $n-1$ intercepts to capture the baseline distribution of responses across the $n$ response levels. The coefficients above it capture the inferred effect of the various predictor variables on the outcome distribution of self-evaluation responses along the 5-point ordinal scale. Ordered logistic models can be read like any regression model, except that the intercepts are given as \emph{log odds ratios}, and the coefficients $\beta_i$ as \emph{difference in log odds} per unit change in the predictor variable. In other words, with every unit change in the predictor, the relative odds ratio of responding in a lower vs. a higher category as given by the intercepts is multiplied by $\exp(\beta_i)$.

Looking at the succession of models in Table~\ref{table:selfresponsesmodelordinal} as well as the pairwise model comparison between them in Table~\ref{table:selfresponsesmodelordinalcomparison}, we first find a strong effect of the type of sociolinguistic variable (model~1): in comparison to the stable negation variant for which the majority of speakers reported using only the `incoming' variant, the imperatives~(\texttt{varimp}) exhibit significantly more responses in the center of the 5-point scale, with the two question types~(\texttt{varynq}, \texttt{varwhq}) falling somewhere in between. While we find no evidence for an effect of informant age across all variables~(model~2) there appears to be an effect of gender, with females being more likely to report increased use of the majority variants~(model~3). % This effect is not particular to the changing variables, adding an interaction is not significant
% TODO include the intermediate age*stable+var (but with no gender) model as well?
When taking into account differences between the different sociolinguistic variables, we do find evidence for an effect of age for the changing variables only.
Rather than using the \texttt{var} term, a 4-level factor that distinguishes all sociolinguistic variables covered by the questionnaire, model~4 adds an interaction between the age coefficient and the \emph{type} of sociolinguistic variable, with the binary \texttt{stable} factor opposing the three changing variables against the stable negation variable.
Even though the model \emph{comparison} between models~3 and~4 in Table~\ref{table:selfresponsesmodelordinalcomparison} is not significant, 
the model coefficient $\beta_{age}=\Sexpr{round(coef(agegenderchangingvarmdl)[["age"]], 3)}$ means that the relative probability of responding in a higher category is multiplied by $\exp(\Sexpr{round(coef(agegenderchangingvarmdl)[["age"]], 3)})=\Sexpr{round(exp(coef(agegenderchangingvarmdl)[["age"]]), 3)}$ for every year that a participant is \emph{older}. This is equivalent to their probability of reporting a relatively higher usage level of the incoming variant \emph{decreasing} slightly (by about \Sexpr{100*(1-round(exp(coef(agegenderchangingvarmdl)[["age"]]), 3))}\%). The coefficient of the \texttt{age:stable} interaction term, which is of a similar amplitude but in the opposite direction~($\beta_{age:stable}=\Sexpr{round(coef(agegenderchangingvarmdl)[["age:stableTRUE"]], 3)}$), implies that this effect of age is effectively cancelled out for the stable control variable.

<<selfresponsesmodel, fig.align="center">>=

# agechanginggendermdl is worse than simple varmdl
#agevarchangingmdl,vargenderchangingmdl
ormtables(nullmdl, varmdl, varagemdl, vargenderagemdl, agegenderchangingvarmdl, fullmdl, of="of participants' own usage estimates.", label="table:selfresponsesmodelordinal")

# second: lme models over the responses as numeric values
#library(lme4)
#linearnullmdl <- lmer(as.numeric(self) ~ (1|id), data=d)
#linearvarmdl <- lmer(as.numeric(self) ~ var + (1|id), data=d)
#linearagemdl <- lmer(as.numeric(self) ~ age + (1|id), data=d)
#linearchangingmdl <- lmer(as.numeric(self) ~ age*stable + (1|id), data=d)
#linearagevarmdl <- lmer(as.numeric(self) ~ age*var + (1|id), data=d)

#linearrandomvarmdl <- lmer(as.numeric(self) ~ age*(1|var) + (1|id), data=d)
# this one's rank deficient
#suppressMessages(linearagevarchangingmdl <- lmer(as.numeric(self) ~ age*stable + var + (1|id), data=d))

#linearhelmertmdl <- lmer(as.numeric(self) ~ age*notchanging + age*notimp + age*notynq + (1|id), data=d)

#ormtable(linearagemdl, linearchangingmdl, linearvarmdl, linearagevarchangingmdl, linearagevarmdl, title="Linear regression model for participants' own usage estimates, converted to a continuous response scale from 1-5.", label="table:selfresponsesmodelnumeric")

#modelcomparisontable(anova(linearnullmdl, linearagemdl, linearchangingmdl, linearvarmdl, linearagevarchangingmdl, linearagevarmdl), of="between the models in Table~\\ref{table:selfresponsesmodelnumeric}", label="table:numericmodelcomparison")
@

<<selfresponsesprediction, fig.cap="Comparison of empirical own usage reports and corresponding model prediction.", fig.subcap=c("Empirical distribution of the self-reported usage levels for the three changing variables, with the participants split into two age groups ($\\le32$ years, $N=39$; $>32$ years, $N=38$). The younger the speaker, the more likely they are to report higher usage of the incoming variant.", "Prediction of response distributions of ordered logistic model (4) from Table~\\ref{table:selfresponsesmodelordinal} for the mean ages of the two age groups plotted above.")>>=
# TODO could include error bars showing amplitude of random participant effect?
# actual data
defaultscales <- list(x=list(tck=1:0, rot=45, alternating=1), y=list(alternating=3))# axs="i"
defaultbarcol <- temp.colors(5)

defaultsettings <- list(strip.border=list(col="black"), strip.background=list(col=c(gray(0.85), gray(0.6))), fontsize=list(text=10))
# layout.heights=list(strip=0.9)
lattice::trellis.par.set(defaultsettings)

# as.table=TRUE for panel draw order
lattice::lattice.options(default.args=list(aspect=0.8), par.strip.text=list(col="black"))#, strip=lattice::strip.custom(strip.names=c(TRUE, TRUE)))

# No mention of 'scales'. But xyplot has an argument 'default.scales' which you can set globally: add this  default.scales = def.scal to the arguments in your xyplot call.
groupedhistogram <- function(formula, ..., data=d, type="percent", scales=defaultscales, col=defaultbarcol, aspect=0.8, xlab="", ylab="responses (%)") { # to count or not to count?
  lattice::histogram(formula, ..., data=data, aspect=aspect, type=type, scales=scales, col=col, xlab=xlab, ylab=ylab, between=list(x=0.7, y=0.7))
}

groupedhistogram(~ self | longvar + agecat, col=temp.colors(5), ylim=c(0, 93))
# main="reported own usage"

#plot(party::ctree(self~loc+age+gender+var+firstvar, data=changing))
# imp branch off first, then neg branches off, predicted by location
#plot(party::ctree(self~loc+age+gender+var+firstvar, data=d))
#Imperatives exhibit higher self-reports of using the outgoing variants~(rightmost node), while most people claim categorical or near-categorical use of the incoming variant for both question types. Within the responses for the two question variables~(left branch), age is a significant predictor of a binary partitioning with a cutoff age of~51, with younger speakers most likely to report using only the incoming variant, and older speakers more likely to select `mostly' the incoming variant.

# .003 coef(rms::orm(self ~ age, data=changing))$stats["Score P"]
#summary(ordinal::clm(self ~ age, data=changing))
#summary(MASS::polr(self ~ age, data=changing))
# random effects eat up a lot of power

#check.orm(d, "self", "age + var", g=3)
#fit <- rms::orm(self ~ age + var, data=changing)
#dd <- rms::datadist(age=d$age, var=d$var)
#options(datadist="dd")
#plot(rms::Predict(fit, age, var), anova=anova(fit))
#check.orm(whq, "self", "age", g=3)

# gender is also significant but only for the self-usage levels (see section at the end)
#rms::lrm(self ~ gender, data=changing)
# negative coefficient for males == women report higher incoming variant usage
#mosaicplot(table(d$var, d$gender, d$self), color=temp.colors(5))
#plot(self ~ gender, data=imp)

# model predictions for all variables

# calculate mean age for each of the three age categories
ages <- round(aggregate(participants$age, by=list(participants$agecat), FUN=mean)$x)

# OLD RMS PREDICTIONS
# effect is mainly driven by whq, but still evident (if not significant) for the other two variables
#predictions <- foreach(v = levels(changing$var), .combine=rbind) %do% {
#  m <- ordinal::clm(self ~ age, data=variable(v))
#  p <- predict(m, expand.grid(age=ages))[[1]]
#  cbind(data.frame(prediction=as.vector(p), response=rep(colnames(p), each=3)), var=v, age=ages)
#}

# fill missing cells with 0s to avoid lattice skipping the colours
#predictions <- aggregate(prediction ~ response + age + var, data=rbind(expand.grid(prediction=0, response=lvls, var=levels(changing$var), age=ages), predictions), FUN=sum)

# apply proper order
#predictions$response <- factor(predictions$response, levels=lvls)

# https://cran.r-project.org/web/packages/ordinal/vignettes/clmm2_tutorial.pdf
# this doesn't work because of the dropped level, use helmert coding instead:
#predictions <- expand.grid(age=ages, var=vars, self=levels(d$self))
predictions <- expand.grid(age=ages, self=lvls, longvar=longvars)
predictions[,helmertvars] <- helmertlevels(as.numeric(predictions$longvar))

predictions$response <- predict(helmertagevarchangingmdl, predictions)

predictions$age <- factor(paste("age=", predictions$age, sep=""), levels=paste("age=", ages, sep=""))

# TODO fix proportions to match above
lattice::barchart(100*response ~ self | longvar + age, data=predictions, col=defaultbarcol, scales=defaultscales, ylab="predicted usage response (%)", ylim=c(0, 93), box.width=1, aspect=0.8, between=list(x=0.7, y=0.7))

#par(mfcol=c(3,3), mar=rep(1,4)))
#rms: p <- predict(m, expand.grid(age=c(20,50,80)), type="fitted.ind")
#sapply(1:3, function(i) barplot(p[i,], main=paste("Prediction for age=", ages[i], sep=""), col=temp.colors(5), ylim=c(0, 0.7)))
@

Finally, fitting a model with separate interaction terms for each of the four variables (by substituting the \texttt{age:stable} term with \texttt{age:var}, model~5) does not improve the model fit significantly, indicating that the presence of the age effect is mostly explained by whether the sociolinguistic variable is undergoing change or not.

To help visualise the effect of age and aid in interpreting the log odd ratio coefficients, the empirical responses by age as well as the corresponding predictions made by the ordered logistic models are shown in Figure~\ref{fig:selfresponsesprediction}. For this purpose we split the responses we collected into two evenly sized age groups, %($\Sexpr{paste(names(table(participants$agecat)), ", N=", table(participants$agecat), sep="", collapse="$; $")}$)
and the distribution of responses per age group and sociolinguistic variable is shown in Figure~\ref{fig:selfresponsesprediction}a: despite differing baseline distributions (with imperatives generally exhibiting a flatter distribution), we can see the general trend of increasing incoming variant usage for younger speakers. The predictions made by model~4 for the different variables and a typical member of each of the two age groups are plotted underneath in Figure~\ref{fig:selfresponsesprediction}b, showing good agreement with the empirical data.

\subsection{`Other people' usage estimates}
\label{sec:otherresponses}

When it comes to reporting on the linguistic usage levels of other individuals in their speech community, the overall pattern of responses is similar to the self-usage estimates, but with an added central tendency or edge-avoiding effect in the responses, as can be seen in Figure~\ref{fig:otherresponses}. This presumably stems from the fact that, when imagining an `average' individual, the informants will model this on the \emph{population average}, which, given any amount of within- or between-individual variation, is almost necessarily non-categorical.

Again, we performed ordered logistic regression models with participant as a random effect, reported in Tables~\ref{table:otherresponsesmodel} and~\ref{table:otherresponsesmodelcomparison}.
In contrast to the self-usage reports, we find no effect of age for any of the variables~(models~1+2). Instead, the models reveal that the only significant predictors of the reported usage levels are the type of sociolinguistic variable~(model~3) as well as the participant's gender, with females again estimating slightly \emph{higher} usage of the incoming variant in the community~(model~4). Importantly we find no significant interaction between the type of variable and any of the other predictors, i.e. the effect of gender again pertains to all four variables, and not just the changing ones~(model~5).

<<otherresponses, fig.cap="Comparison of own vs community-level usage estimates by binary gender.", fig.subcap=c("Overall distribution of reported \\emph{own} usage, per sociolinguistic variable.", "Responses to the question ``How much do you think are people around you using either of the variants?''. While the distribution of responses to the imperative question is again consistently flatter than for the other responses, in comparison to the self-usage estimates shown in (a) there is a clear shift away from both of the extreme response options, indicating that individuals perceive the population average to be variable rather than categorical.")>>=

# main="Estimated own usage of the competing variants"
#groupedhistogram(~ self | longvar, data=d, layout=c(4,1), ylim=c(0, 85))
groupedhistogram(~ self | longvar + gender, ylim=c(0, 90))

# main="Estimated population-wide usage of the competing variants"
# main="reported community usage"
groupedhistogram(~ other | longvar + gender, data=d, ylim=c(0, 90))

#fourboxplots(age ~ other)
#groupedhistogram(~ other | longvar + agecat, data=changing, ylab="actual usage response (%)", ylim=c(0, 85))
# age only significant for y/n questions
# report that questions pattern together and imp+neg pattern together?

nullmdl <- clme(other ~ 1, random=id)
#gendermdl  <- clme(other ~ gender, random=id)
agemdl <- clme(other ~ age, random=id)
# this is worse than the simple gendermdl which has higher df
agechangingmdl <- clme(other ~ age*stable, random=id)
varmdl <- clme(other ~ var, random=id)
vargendermdl  <- clme(other ~ var + gender, random=id)

# switching the order of variables around here makes finding of start values fail...?
suppressWarnings(vargenderchangingmdl <- clme(other ~ var + gender*stable, random=id))

#helmertvarmdl <- clme(other ~ notchanging + question + whq, random=id)
#agevarmdl <- clme(other ~ age*var, random=id)
# this one's rank deficient
#suppressWarnings(agevarchangingmdl <- clme(other ~ age*stable + var, random=id))
# need this for the prediction
#helmertagevarchangingmdl <- clme(other ~ age*notchanging + question + whq, random=id)

ormtables(nullmdl, agemdl, agechangingmdl, varmdl, vargendermdl, vargenderchangingmdl, of="predicting participants' answers to the question ``How much do you think are people around you using either of the variants?''", label="table:otherresponsesmodel")
@

The data from the first two questions implicitly contains another piece of information, namely where the speakers regard their own variable usage to be relative to the community-level. We measure this by looking at the number of ordinal categories along the 5-point scale that the self-usage response \emph{differs} from the reported community-level usage, and subtracting their ordinal ranks. In this representation of the relative difference, positive numbers indicate that a speaker reported a relatively higher usage of the incoming variant for themselves than for the community, and vice versa.
% this representation collapses different responses, e.g. +3 can mean 'older only out, younger more in' as well as 'older mostly out, younger only in', 0 could be 'older usage = younger usage' for any of the 5 usage levels

If we look at the distribution of this measure in Figure~\ref{fig:selfdiff}, we see that the participants' age is a good predictor of this difference between themselves and the community. %The binary partitioning suggested by conditional inference shows that the majority of under-58-year-olds regard themselves as `ahead' of their community in terms of using the incoming variants, whereas those over 58 are most likely to report being level with the community~(
Ordinal logistic regression models paralleling those fit to the self-usage reports in Table~\ref{table:selfresponsesmodelordinalcomparison} above confirm this picture: as can be seen in Tables~\ref{table:selfdiffmodel} and~\ref{table:selfdiffmodelcomparison}, the most parsimonious model predicts the difference between individuals' reported own and community usage based on the type of sociolinguistic variable as well as the informant's age. Although the effect of age is again greater for the changing variables~(compare models~2 and~3), the models indicate no significant difference between the stable as opposed to any of the changing variables~(models~3+4).

<<selfdiff, fig.cap="Relative difference in number of ordinal categories between participants' reported \\emph{own} vs community usage levels of the competing variants, by sociolinguistic variable and age group. Positive numbers indicate that a speaker reported a higher usage of the incoming variant for themselves than for the community, and vice versa. While the 5-point response scale allows for differences of up to $\\pm4$, no speaker indicated their own usage to be more than two ordinal categories away from the community level. Younger speakers are more likely to perceive themselves to be ahead of the community level usage~(more red), while older speakers are most likely to report their usage to be level with the community~(white) or behind~(blue).">>=
# TODO exclude whalsay data points? also show full +-4 scale and don't truncate at 2?
groupedhistogram(~ selfdiff | longvar + agecat, data=d, col=temp.colors(9), ylim=c(0, 85), xlab="difference score", drop.unused.levels=FALSE) # , xlab="difference in number of ordinal categories between individuals' 'self' and 'other' reponses"

#counts <- table(d$selfdiff, d$var)
#par(xpd=NA, mar=par("mar")+c(0,0,0,3))
#barplot(counts, legend=rownames(counts), col=temp.colors(-2,4), xlab="sociolinguistic variable", ylab="no. of responses", args.legend=list(x="topright", inset=c(-0.23,-.1), title="Relative difference\nof 'self' usage\nminus 'community' usage", bty="n"), bty="l")

#plot(party::ctree(selfdiff~loc+age+gender+firstvar+condition, data=changing))
#check.orm(subset(d, var!="neg"), "selfdiff", "age")

# gender is NOT significant for selfdiff
nullmdl <- clme(selfdiff ~ 1, random=id)
agemdl <- clme(selfdiff ~ age, random=id)
# TODO FIXME need to include location here OR filter out whalsay speakers?
#agepluschangingmdl <- clme(selfdiff ~ age+stable, random=id)
#agechangingmdl <- clme(selfdiff ~ age*stable, random=id)
varmdl <- clme(selfdiff ~ var, random=id)
ageplusvarmdl <- clme(selfdiff ~ age+var, random=id)
agevarmdl <- clme(selfdiff ~ age*var, random=id)
# this one's rank deficient
suppressWarnings(agevarchangingmdl <- clme(selfdiff ~ age*stable + var, random=id))
# need this for the prediction
helmertagevarchangingmdl <- clme(selfdiff ~ age*notchanging + question + whq, random=id)

ormtables(nullmdl, varmdl, ageplusvarmdl, agevarchangingmdl, agevarmdl, of="of the relative difference between participants' reported own and community-level usage.", label="table:selfdiffmodel")

# old plot style
#library(variant ioplot)
#vioplot(subset(changing,selfdiff==-2)$age, subset(changing,selfdiff==-1)$age, subset(changing,selfdiff==0)$age, subset(changing,selfdiff==1)$age, subset(changing,selfdiff==2)$age)

# caption: Age distribution of the difference between reported self and community-level usage. 
#b <- boxplot(age ~ selfdiff, data=changing, plot=0)
#boxplot(age ~ selfdiff, data=changing, xlab="difference between reported self vs. community-level usage", ylab="participant age (years)", names=paste(b$names, " (n=", b$n, ")", sep=""), col=temp.colors(9), drop.unused.levels=FALSE)
#points(jitter(as.numeric(changing$selfdiff)), changing$age, pch=20, col=changingcolors[changing$var])
#legend("topleft", legend=levels(changing$var), horiz=T, fill=changingcolors)
@

\subsection{Beliefs about the age of competing linguistic variants}
\label{sec:oldervar}

%Before explicitly drawing attention to the fact that the linguistic variables are changing~(and that this might be reflected in apparent time differences),
The third question of the questionnaire aimed at eliciting the speakers' beliefs about the variants by explicitly asking which they thought was the `older' of the two, with `people have always used both' given as a neutral third option. As can be seen in Figure~\ref{fig:variantage}, people reliably identify the outgoing variant as the `older' one for the three changing variables. For the stable negation variable results are more mixed, but many also report the less widespread `didnoo' variant as being older.

The ordered logistic regression models reported in Tables~\ref{table:variantagemodel} and~\ref{table:variantagemodelcomparison} show that, while participants generally tend to report the less frequent variants to be older, they are more likely to do so for the three changing variables~(model~3). There is also again a significant interaction between the type of variable and the age of the informant: older informants are more likely to identify the outgoing variant as the `older' one, but again only for the sociolinguistic variables that are changing~(models~2-5). Beyond the split between the stable and changing variables, there was no significant difference between the individual variables~(models~3-6), and we also found no evidence for any effect of gender. % not reported

%While the consistency of individual responses indicate that the community shares common beliefs about the \emph{directionality} of these changes, this result does not speak to the source of these beliefs. We will return to this issue in the Discussion.

<<variantage, fig.cap="Distribution of responses to the question ``Which of the two variants do you think is \\emph{older}?'', split by sociolinguistic variable and age of the informant. In comparison to the stable negation variant, where about half of the people considered the geographically more limited (minority) variant `didnoo' to be older, the response distribution was more extreme for the three changing variables. Here, around 80\\% of respondents report the outgoing forms (which are already the minority forms) to be older, with even fewer answers falling on the majority variant as well as the ``people have always used both'' option.">>=
# TODO not actually true: At least for the changing variables, older informants are more likely to identify the outgoing variant as the `older' one, as confirmed by the models in Tables~\\ref{table:variantagemodel} and~\\ref{table:variantagemodelcomparison}.
# (TODO include N per variable?)
#$N=\Sexpr{colSums(table(d$oldervarfreq, d$var))}$

groupedhistogram( ~ oldervar | longvar + agecat, data=d, col=temp.colors(3, intensity=0.5), ylim=c(0, 90))
# xlab="Which of the variants do you think is older?"

# these should be reported as a multinomial logistic, not ordinal, although
# underlyingly the model fitting is the same (see documentation of clm2):
# https://cran.r-project.org/web/packages/ordinal/ordinal.pdf
ovnullmdl <- clme(oldervar ~ 1, random=id)
agemdl <- clme(oldervar ~ age, random=id)
gendermdl <- clme(oldervar ~ gender, random=id)
ovstablemdl <- clme(oldervar ~ stable, random=id)
varmdl <- clme(oldervar ~ var, random=id)
stableplusgendermdl <- clme(oldervar ~ stable+gender, random=id)
#stablegendermdl <- clme(oldervar ~ stable*gender, random=id)
#vargendermdl <- clme(oldervar ~ var+gender, random=id)
#vargendermdl <- clme(oldervar ~ var*gender, random=id)
stableplusagemdl <- clme(oldervar ~ age+stable, random=id)
stableagemdl <- clme(oldervar ~ age*stable, random=id)

# none of those improve
suppressWarnings(changingvarmdl <- clme(oldervar ~ age*stable + var, random=id))
#varagemdl <- clme(oldervar ~ age*var, random=id)
#fullmdl <- clme(oldervar ~ age*stable + var + gender, random=id)

# neither var*gender nor age*var are good/worth including
# varmdl and stablegendermdl after stablemdl
# gendermdl and agemdl both crap

# TODO stableplusagemdl missing
ormtables(ovnullmdl, gendermdl, agemdl, ovstablemdl, varmdl, stableagemdl, changingvarmdl, of="of responses to the question ``Which of the two variants do you think is \\emph{older}?''.", label="table:variantagemodel")

# There is a significant difference in response distributions between the three changing variables and the stable negation variable (model 1), but none between the changing variables themselves (model 2).

#model <- party::ctree(oldervarfreq ~ loc+age+gender+firstvar+firstolder+condition+var, na.omit(d))
#plot(model, terminal_panel=party::node_barplot(model, fill=temp.colors(3, intensity=.7), id=F))
#plot(oldervarfreq ~ var, d)
# responses to the two question types are *not* significantly different from the imperative responses:
#rms::lrm(oldervarfreq ~ var, data=changing)

# age is a significant predictor for answers to the negation variable (with)
#rms::lrm(oldervarfreq ~ age+gender+firstvar+firstolder+condition, data=neg)
# no significant predictors for the changing variables
#rms::lrm(oldervarfreq ~ loc+age+gender+firstvar+firstolder+condition+var, data=changing)
@

\subsection{Perception of apparent time differences}
\label{sec:apparenttime}

The final pair of questions, which ask for the participants' impression of the relative usage level of the two competing variants by `younger' and `older' speakers was aimed at helping us to determine whether individuals can perceive and report apparent time differences in categorical variables. As can be seen in Figure~\ref{fig:apparenttime}, speakers consistently report higher usage of the majority variants among younger speakers but, surprisingly, this effect is present across all sociolinguistic variables, including the stable control.
%Interestingly, hardly anyone attributed higher usage of the majority variant to older speakers, so that $0$ works as a `hard edge'
While there appears to be a general trend to attribute the usage of minority variants (whether outgoing or just geographically limited) to older speakers, the ordinal logistic regression model~2 in Tables~\ref{table:apparenttimemodel} and~\ref{table:apparenttimemodelcomparison} shows that the effect is significantly stronger for the three changing variables, but with no significant differences between them~(compare models~3+4).
In contrast to the responses to question~3, the age of our informants does not appear to have a systematic effect on how they perceive apparent time differences for any of the variables under investigation~(models~1+4).
% TODO report responses to individual q4+5 answers: only type of variable makes a difference!

<<apparenttime, fig.cap="Relative difference between the reported usage of the two variants between `older' and `younger' speakers, for each of the four variables. The relative difference indicates the number of ordinal categories that separates an individuals' responses for the two age groups along the 5-point scale, where positive numbers (in shades of red) correspond to reporting higher usage of the majority variant among younger speakers, and vice versa. The most extreme points of the scale at $\\pm4$ correspond to reporting the `older' and `younger' speakers to be categorical users of opposing variants, the mid-point at $0$ to reporting the same usage levels for both.">>=
# Response `0' means that the informant reported the same usage levels for both the `older' and `younger' speaker groups, reponse `1' means that younger speakers were reported to be one ordinal category more advanced in their usage of the incoming variant, etc.

groupedhistogram(~ apparentdiff | longvar, data=d, xlab="difference score", layout=c(4, 1), drop.unused.levels=FALSE, col=temp.colors(9), ylim=c(0, 48))

# individual younger/older responses: only variable makes a difference, nothing else!
nullmdl <- clme(old ~ 1, random=id)
varmdl <- clme(old ~ var, random=id)
ordermdl <- clme(old ~ var+firstvar, random=id)
varagemdl <- clme(old ~ var+age, random=id)
vargendermdl <- clme(old ~ var+gender, random=id)
suppressWarnings(stablemdl <- clme(old ~ var+age*stable, random=id))
#modelcomparison(nullmdl, varmdl, ordermdl, vargendermdl, varagemdl, stablemdl)

# same thing with young responses
nullmdl <- clme(young ~ 1, random=id)
# only works with clm2, not clmm2: ordinal:::addterm.clm2(nullmdl, young ~ var+firstvar+gender+stable+age, test="Chisq")
varmdl <- clme(young ~ var, random=id)
ordermdl <- clme(young ~ var+firstvar, random=id)
varagemdl <- clme(young ~ var+age, random=id)
vargendermdl <- clme(young ~ var+gender, random=id)
# doesn't converge: stablemdl <- clme(young ~ var+age*stable, random=id)
#modelcomparison(nullmdl, varmdl, ordermdl, vargendermdl, varagemdl)


# oldervarfreq is NA for one negation answer, so na.omit()

nullmdl <- clme(apparentdiff ~ 1, random=id, data=na.omit(d))
agemdl <- clme(apparentdiff ~ age, random=id, data=na.omit(d))
gendermdl <- clme(apparentdiff ~ gender, random=id, data=na.omit(d))
stablemdl <- clme(apparentdiff ~ stable, random=id, data=na.omit(d))
#stablegendermdl <- clme(apparentdiff ~ stable * gender, random=id, data=na.omit(d))
#modelcomparison(nullmdl, agemdl, stablemdl, stablegendermdl)
#oldervarmdl <- clme(apparentdiff ~ oldervar, random=id, data=na.omit(d))
varmdl  <- clme(apparentdiff ~ var, random=id, data=na.omit(d))
#stablegendermdl <- clme(apparentdiff ~ stable+gender, random=id, data=na.omit(d))
#vargendermdl <- clme(apparentdiff ~ var+gender, random=id)
#stableplusagemdl  <- clme(apparentdiff ~ age+stable, random=id, data=na.omit(d))
stableagemdl <- clme(apparentdiff ~ age*stable, random=id, data=na.omit(d))
#suppressWarnings(changingvarmdl <- clme(apparentdiff ~ age*stable + var, random=id))
#varagemdl <- clme(apparentdiff ~ age*var, random=id)
q3mdl <- clme(apparentdiff ~ stable+oldervar, random=id, data=na.omit(d))
# neither age nor gender help more than that
#q3mdl2 <- clme(apparentdiff ~ stable+oldervar +age, random=id, data=na.omit(d))
#q3mdl2 <- clme(apparentdiff ~ age*stable+oldervar, random=id, data=na.omit(d))

# agemdl/stableagemdl bad, gender bad, varmdl also bad but could include anyway
ormtables(nullmdl, agemdl, stablemdl, varmdl, stableagemdl, q3mdl, of="of the relative difference in individuals' estimates for `younger' and `older' speaker groups in number of ordinal categories, a proxy for perceived apparent time differences. Raw data is shown in Figure~\\ref{fig:apparenttime}.", label="table:apparenttimemodel")

# same result for relative difference
#nullmdl <- clme(apparentrelative ~ 1, random=id, data=na.omit(d))
#agemdl <- clme(apparentrelative ~ age, random=id, data=na.omit(d))
#stablemdl <- clme(apparentrelative ~ stable, random=id, data=na.omit(d))
##varmdl  <- clme(apparentrelative ~ var, random=id, data=na.omit(d))
#q3mdl <- clme(apparentrelative ~ stable+oldervarfreq, random=id, data=na.omit(d))
#ormtables(nullmdl, agemdl, stablemdl, q3mdl, of="of the relative relative #difference in individuals' estimates for `younger' and `older' speaker groups in number of ordinal categories, a proxy for perceived apparent time differences.", label="table:apparenttimemodel2")

#counts <- table(d$apparentdiff, d$var)
# truncate count table so as not to include irrelevant colours
#rng <- range(which(rowSums(counts)>0))
#counts <- counts[rng[1]:rng[2],]
#par(xpd=NA, mar=par("mar")+c(0,0,0,3))
#barplot(counts, legend=rownames(counts), col=temp.colors(min(as.numeric(rownames(counts))), max(as.numeric(rownames(counts)))), xlab="sociolinguistic variable", ylab="no. of responses", args.legend=list(x="topright", inset=c(-0.18,-.1), title="Relative difference\nof 'younger' usage\nminus 'older' usage", bty="n"), bty="l")
# 'young' and 'old' responses are significantly different between imp vs. questions
#rms::orm(young ~ var, data=changing)
#plot(party::ctree(young ~ loc+age+gender+firstvar+firstolder+condition+var, changing))
#rms::orm(old ~ var, data=changing)
#plot(party::ctree(old ~ loc+age+gender+firstvar+firstolder+condition+var, changing))

# this indicates that their apparent time diff answers aren't *just* due to
# their answer to question 3. but are the informants consistent between the
# population average and younger/older questions??
# TODO plot distribution of other-young and other-old - should've done this on
# separate pages so people can't look back and be uber-consistent!!

# BUT the apparent age difference pattern is similar for all three variables
#rms::orm(apparentdiff ~ var, data=changing)
#check.orm(changing, "apparentdiff", c("var", "age", "gender"))
# response to older speakers question significantly predicted by previously chosen older var
#rms::orm(old ~ oldervar, data=changing)
# response to younger speakers doesn't appear to be affected
#rms::orm(young ~ oldervar, data=changing)

# what predicts people's answers to the apparent time differences?
# gender not significant at all
#rms::lrm(apparentdiff ~ gender, data=changing)
# the only thing is a possible ordering effect
#rms::lrm(apparentdiff ~ firstvar, data=changing)
@

While this might suggest that individuals can accurately perceive and report on apparent age differences in changing categorical variables, we cannot straightforwardly jump to this conclusion. Model~5 shows that our participants' responses to question~3 (i.e. their reported belief about which if any of the competing variants is `older') %, and in particular the `wrong' classification of the incoming variant as the `older' one
is a significant predictor of how far they reported younger speakers to be `ahead' or `behind' in their relative usage of the incoming variant.
So while all results presented so far show that individuals are clearly able to (correctly) report on the directionality of the changes under investigation, the exact \emph{source} of this metalinguistic knowledge is still in question. We turn to this issue in our discussion.

\section{Discussion}

Having presented the questionnaire data as well as statistical models of the individual responses, we now turn our attention to the particular research questions and predicted effects discussed in Section~\ref{sec:questionnairepredictions}.

\subsection{Identifying the source of awareness of ongoing changes}
\label{sec:questionorder}

The main goal of our research was to quantify if and to what degree individuals are aware of and able to report on the direction of ongoing changes in their community, with a particular eye on whether individuals are sensitive to differences in `apparent time', i.e.~the traditionally more advanced usage of incoming variants among younger speakers.
While the results presented in Sections~\ref{sec:oldervar} and~\ref{sec:apparenttime} indicate that people have accurate knowledge about ongoing changes, our data does not allow us to give a definite answer regarding the \emph{source} of this knowledge.
In principle, beliefs could be based on any or all of (a)~meta-linguistic commentary or other connotations of variants being archaic, (b)~impressions of the change in \emph{real time}, i.e.~awareness of changing speech patterns that accumulate throughout a speaker's lifetime, or (c)~apparent time differences in variable usage across age groups.
%The present challenge is to identify, if possible, the source of
The questionnaire was designed with these different sources of knowledge in mind. In particular, while questions 4+5 tapped into speakers knowledge about apparent time differences between speakers, the responses to question~3 offer a more general window into individuals' folk-linguistic beliefs about the `age' or novelty of the competing variants.

As already indicated above, the two measures turned out to be highly correlated: model~(5) in Table~\ref{table:apparenttimemodel} showed the folk-linguistic belief about variant age is itself a good predictor of individuals' perceived apparent time differences, as derived from questions 4+5.
%Conversely, we can expand the models predicting people's reports about the perceived age of variant (model 4 from Tables~\ref{table:variantagemodel} and~\ref{table:variantagemodelcomparison}) by adding the perceived apparent time difference that we can extrapolate from questions 4+5.
Importantly, the converse is also true: Tables~\ref{table:oldervarq3model} and~\ref{table:oldervarq3modelcomparison} report expanded models of individuals' responses to question~3, showing that the apparent time differences gathered from the responses to questions 4+5 are a good predictor of the responses to question~3. The number of ordinal categories between the reported `older' and `younger' usage levels~(coded as a continous variable~\texttt{apparentdiffN}) is in fact a better predictor of the participants' folk-linguistic belief than whether the variable is actually changing or not~(compare models~1 and~2).
What the models do not suggest, however, is that folk-linguistic beliefs are based on perceived apparent time differences alone~(model~3). Other predictors remain significant, in particular the interaction between informant age and the type of sociolinguistic variable reported earlier in Section~\ref{sec:oldervar}. Even when the participants' impression of apparent age differences is taken into account, there is still a significant effect of informant age on their responses, with older participants less likely to report the less frequent variant as older for the stable control variable only~(compare models~4 and~5).
%The effect does not completely outweigh the role of variable however, instead the effect of these two factors appears to be cumulative.

Based on these results it remains an open question whether people might have inferred their answer to question~3 independently from a perceived apparent time difference, or if participants felt led to answer questions~4 and 5 in a way that would post-hoc justify their earlier response, which was itself based on other~(socio-indexical) knowledge.
In order to understand the different sources of socio-indexical knowledge that might be at play here, it is insightful to take a closer look at the responses to our control variable.

<<oldervarq3model>>=
apparentdiffmdl <- clme(oldervar ~ apparentdiffN, random=id)

stableapparentdiffmdl <- clme(oldervar ~ stable + apparentdiffN, random=id)
# not significant at all (because stable and apparentdiff are highly correlated)
#stableapparentdiffmdl2 <- clme(oldervar ~ stable * apparentdiffN, random=id)
#modelcomparison(stableapparentdiffmdl, stableapparentdiffmdl2)
#agediffmdl <- clme(oldervar ~ age + apparentdiffN, random=id)
stableplusagediffmdl <- clme(oldervar ~ age + stable + apparentdiffN, random=id)
stableagediffmdl <- clme(oldervar ~ age*stable + apparentdiffN, random=id)

# everything here is better than stableagemdl (model 3 from Table \ref{table:variantagemodel})

ormtables(ovnullmdl, ovstablemdl, apparentdiffmdl, stableapparentdiffmdl, stableplusagediffmdl, stableagediffmdl, label="table:oldervarq3model", title="Extension of the ordered logistic regression model in Table~\\ref{table:variantagemodel}, adding individuals' perceived apparent time difference as an additional predictor for their responses tothe question ``Which of the two variants do you think is older?''.")
@

%So while there is strong correlation between the folk-linguistic beliefs and perceived apparent time differences, our analysis suggests that it might not be possible to reduce either of them to the other: in both models other predictors are highly significant, showing that the responses mutual influence explains some, but not all of the effect.

%While we can't derive a definite answer, there is at least some indication that both sources -- apparent time differences and folk-linguistic beliefs -- are at play in answering the respective other question.

%Conversely, the direction of the relative ordinal difference between the reported younger/older speaker usage is also a significant predictor of the answer to the preceding ``Which of the two variants do you think is \emph{older}?'' question~(model 2), with a reported apparent time difference~(i.e.~an ordinal difference~$>0$) predicting increased identification of the outgoing variant as the `older' one.

%One potential way to find out whether the latter is the case is by checking whether the absolute progression of the changes, where the imperatives seem to lag behind a bit, is also evident in the answers about the specific age group questions. The overall pattern of relative apparent age differences does not differ for the questions vs. the imperatives TODO redo this
% i.e.check whether people's young/old responses are better predicted by their self/other responses or by oldervar?

<<q3effects>>=
nullmdl <- clm2(young ~ 1, data=na.omit(d))
# even when both 'other' and 'var' are used as baseline, 'oldervar' still explains some of the shift
#nullmdl <- clm2(young ~ other+var, data=na.omit(d))
#addterm(nullmdl, young ~ firstvar + firstolder + old + age + stable + var + oldervar + self + other, sorted=TRUE, test="Chisq")
# ordering of young/old group first has no effect
nullmdl <- clm2(young ~ firstolder + oldervar, data=na.omit(d))
#addterm(nullmdl, young ~ firstvar + firstolder*oldervar + old + age + stable + var + self + other, sorted=TRUE, test="Chisq")

# for the 'older' speaker group on the other hand, oldervar is a better predictor than even 'var' and 'other'!
nullmdl <- clm2(old ~ 1, data=na.omit(d))
#addterm(nullmdl, old ~ firstvar + firstolder + young + age + var + oldervar + self + other, sorted=TRUE, test="Chisq")
# even when both 'other' and 'var' are used as baseline, 'oldervar' still explains some of the shift
#nullmdl <- clm2(young ~ other+var, data=na.omit(d))

# 'other' is generally much much better at predicting than 'self'
#modelcomparison(clme(old ~ var + oldervar, random=id, data=d), clme(old ~ var + oldervar + other, random=id, data=d))

# ordering of young/old group first has no effect
#nullmdl <- clm2(old ~ firstolder + oldervar, data=na.omit(d))
#addterm(nullmdl, old ~ firstvar + firstolder*oldervar + old + age + stable + var + self + other, sorted=TRUE, test="Chisq")

# best predictors of apparentdiff
nullmdl <- clm2(apparentdiff ~ 1, data=na.omit(d))
# best predictor is 'old', which subsumes most of the power of 'oldervar'
#nullmdl <- clm2(apparentdiff ~ old + other + var, data=na.omit(d))
#addterm(nullmdl, apparentdiff ~ firstvar + firstolder + old + age + var + oldervar + self + other, test='Chisq', sorted=TRUE)
@

\subsection[Variant age and perceived apparent time differences]{Variant age and perceived apparent time differences: evidence from the control variable}

Some more evidence regarding the primary source of inividuals' knowledge can be glanced from the responses to our control variable. As the distribution of negation variants on Shetland is stable, determined by geography rather than by generational change, we would not expect any information on the history of the two variants to be available to our speakers.
Regarding their answers to the first two questions, the control patterned as expected. Own usage reports were predicted perfectly by geographical location, with all four participants indicating categorical usage of the `noo' variant~(coded as `outgoing' in the Figures) coming from the isle of Whalsay. The estimates of the community-wide usage consequently fell chiefly in the `more incoming' category, with no clear internal patterning of responses along any of the participant variables~(see Figure~\ref{fig:otherresponses}).

<<stablemodels>>=
# predicting the older variable:
# for negation only - age!
#suppressMessages(library(MASS))
suppressWarnings(library(ordinal))

nullmdl <- ordinal::clm(oldervar ~ 1, data=neg)
nullmdl <- ordinal::clm(oldervar ~ as.numeric(apparentdiff), data=neg)
# addterm on "clm" gives Hessian warnings, while it doesn't for "clm2"?
#addterm(nullmdl, oldervar ~ as.numeric(apparentdiff) + age + gender + condition + firstvar + loc + self + other + selfdiff, test="Chisq", sorted=TRUE)

# for changing data, age n.s., 'self' significant for whq
nullmdl <- ordinal::clm2(oldervar ~ 1, data=changing)
#addterm(nullmdl, oldervar ~ var + age + gender + condition + firstvar + loc + self + other + selfdiff, test="Chisq", sorted=TRUE)
# confirmed by fitting mixed effects model to changing data only
#modelcomparison(clme(oldervar ~ 1, random=id, data=changing), clme(oldervar ~ age, random=id, data=changing))

#agemdl <- rms::orm(oldervar ~ age, data=neg)
#agemdl <- ordinal::clm(oldervar ~ as.numeric(apparentdiff)+age, data=neg)
#anova(nullmdl, agemdl)
@

%Since age does not affect the reported self-usage levels of the negation variable, and the reported community-level usage is consistent for all variables, there is consequently no effect of age on how much people report to use the negation variants relative to their surrounding community.
When it came to beliefs about the relative age of the two negation variants in question~3 we found that, despite the apparent absence of any evidence for it, almost half of the participants stated that they believed that the geographically limited negation variant was `older' than its more widespread counterpart, as could be seen in Figure~\ref{fig:variantage}.
This result is puzzling: the geographical distribution of the two variants is well-known to Shetland inhabitants, an assumption that was confirmed by the fact that 17~out of 77~participants used the optional comment field to point out that the variable realisation of negation patterned geographically and not by time, the dimension investigated by the questionnaire. %(one participant in the on-site paper-based version of the questionnaire even omitting this question, instead noting the geographical pattern as a side comment).

% TODO mention that apparent time diff is best predictor, but adding age still improves the model significantly~($p=\Sexpr{format.p.value(anova(nullmdl, agemdl)[["Pr(>Chisq)"]][-1])}$) % TODO include Chisq stats?
%While this result in itself requires explanation, we also observed an additional interaction with age, indicating that the age of the participant affected their beliefs about the stable variables different from the changing ones.
%Fitting a simple ordered logistic regression model to the negation data only confirms a significant effect of age, with older participants \emph{less} likely to identify the localised minority variant as the older one~($p=\Sexpr{format.p.value(agemdl$stats["Score P"])}$).
%In terms of perceived age of the variants, the only significant age effect is actually with the stable negation variable, where older people are more likely to identify the geographically more widespread `didnoo' variant as being the `older' one~(caveat: that is still only 8 out of 76 people, and those 8 happen to contain relatively older speakers).
%rms::orm(oldervarfreq ~ age+gender+firstvar+firstolder+condition, data=neg)


%A similarly intriguing result can be obtained from the perceived apparent time differences derived from the participants' answers to questions 4+5. 
The distribution of perceived apparent time differences for our control revealed a similarly intriguing result: as the negation variable isn't changing we would have expected the distribution of difference scores to be centered around the zero mark.
While Figure~\ref{fig:apparenttime} showed that identical estimates for the `older' and `younger' speaker groups was indeed the most frequently reported result across all our participants, the overall distribution of responses is skewed towards reporting higher usage of the more widespread variant for younger speakers, with almost no apparent time differences reported in the opposite direction.

<<stablemodels2>>=
# FIXME this is already numeric by here?
nullmdl <- ordinal::clm(apparentdiff ~ 1, data=na.omit(neg))
# mainly predicted by previous answers
#nullmdl <- ordinal::clm(apparentdiff ~ oldervar, data=na.omit(neg))
#addterm(nullmdl, apparentdiff ~ oldervar + age + gender + condition + firstvar + loc + self + other + selfdiff, test="Chisq", sorted=TRUE)

# the interaction between the apparent time difference and type of variable isn't quite significant
#modelcomparison(clme(oldervar ~ as.numeric(apparentdiff)+stable, random=id), clme(oldervar ~ as.numeric(apparentdiff)*stable, random=id))
# the interaction between folk belief and variable type isn't at all
#modelcomparison(clme(apparentdiff ~ oldervar+stable, random=id), clme(apparentdiff ~ oldervar*stable, random=id))
@

This raises the question of why speakers would extrapolate from a geographical pattern to history, or at least to the historical origin of variants. While there is currently no evidence that the relative usage of the more localised negation variant is decreasing~(Jamieson, p.c.), it is imaginable that it shares a few meta-linguistic features with the outgoing variants of the changing variables. As the more `local' variant, it could have gathered connotations of `dialectality' and `authenticity' that are typically associated with older speakers. %~(TODO are there results regarding whether this is generally the case, sociolinguistically? Is there any particular reason to believe this might be true on Shetland?).
This (possibly imagined) prevalent usage among older speakers could in turn give rise to both effects observed in the responses: firstly, it could be regarded to speak to the variant's historical primacy~\citep{Bailey2002}, and secondly, the usage pattern by authentic `older' speakers stands in natural opposition to younger speakers, explaining the reported differences in apparent time, an effect that was possibly amplified by the ordering of questions in the survey.

As it stands, it is not possible for us to identify the exact pathway of these socio-indexical connotations. Does `authenticity' speak to both speaker group differences \emph{and} variant history, or does one affect the other?
While the responses to the changing variables provide evidence that apparent time differences are perceived independently, we can again not rule out that the responses to questions~4+5 were influenced so as to provide a post-hoc justification of the earlier answer regarding the variants' relative age. Conversely, the presence of seemingly non-substantiated beliefs about variant age for the control variable might indicate that, when forced to identify one variant as `older', our participants might attribute historical primacy based on imagined age stratification even when they know that, synchronically, usage is determined by geography alone.

To avoid the same problem and aid in identifying the influence of either type of knowledge, an improved methodology should therefore randomise the order of questions~3~vs.~4+5 between individuals.% and, time allowing, also embed~4+5 in a bigger set of distractor questions.
The two randomisations could then serve as separate conditions:
measuring the effect of first explicitly drawing attention to either linguistic history \emph{or} apparent time differences between participants would allow us to quantify what effect either meta-linguistic dimension has on the other.

%This result could indicate that answers about the age of the variants were based on perceived differences in the apparent time distribution, but it could also be
%Does this mean that we should think of the causality as going from answering apparent time differences to folk-linguistic beliefs about variant age, and not vice versa?

% TODO gotta fit something about the subsets??
%subset(d, firstolder==TRUE)

%Despite the fact that up to this point in the questionnaire we avoided to draw explicit attention to such differences

<<apparenttimepervariantage, fig.cap="Reported apparent time difference per answer to the 'which variant do you think is older' question. While at least some of the apparent time responses for the changing variables go away when the participants did not report having any age beliefs, the apparent time reports disappear much more strongly for the negation, indicating that the reported differences may have been driven by the preceding question only.", fig.subcap=c("a", "b")>>=
# TODO Still outstanding is a test against the underlying baseline distributions given the responses, which are plotted below

#plot(party::ctree(apparentdiff ~ oldervar + var + var*oldervar, data=d))

#table(changing$oldervar, changing$apparentdiff)
# TODO redo with table() and normal hist() (percent) plots that include the n per oldervar response (because highly skewed)
#groupedhistogram( ~ apparentdiff | oldervar*stable, data=d, col=temp.colors(9), drop.unused.levels=FALSE, main="stable vs. changing variables")
#groupedhistogram( ~ apparentdiff | oldervar, data=changing, col=temp.colors(9), drop.unused.levels=FALSE, main="changing variables", layout=c(3,1))

#obliviousneg <- subset(neg, oldervar=="same")
#obliviouschanging <- subset(changing, oldervar=="same")

# .006
#wilcox.test(as.numeric(obliviousneg$old), as.numeric(obliviousneg$young))
# 7e-9
#wilcox.test(as.numeric(obliviouschanging$old), as.numeric(obliviouschanging$young))

plotapparentdiffbaseline <- function(d)
  barplot(diffchancelevels(table(d$old)/nrow(d), table(d$young)/nrow(d)), col=temp.colors(9), ylab="Difference")

#par(mfrow=c(3,2))
#plotapparentdiffbaseline(neg)
#plotapparentdiffbaseline(changing)
#plotapparentdiffbaseline(subset(neg, oldervar=="out"))
#plotapparentdiffbaseline(subset(changing, oldervar=="out"))
#plotapparentdiffbaseline(subset(neg, oldervar=="same"))
#plotapparentdiffbaseline(subset(changing, oldervar=="same"))
@

\subsection{Between-participant differences: age}

Our results revealed several significant effects of the informants' age on their responses: firstly, age is a good predictor for participants' reported self-use of the changing variables, as reported in Section~\ref{sec:selfresponses}. In combination with the fact that age did not seem to affect participants' estimates of the community-level usage,
age is consequently a good predictor for how much the respondents think they are `ahead' or `behind' their estimated community level usage, as measured by the relative difference between people's estimated self and community usage levels~(Section~\ref{sec:otherresponses}). This suggests that individuals can correctly identify where, during an ongoing change, they are positioned relative to the rest of the community.

While \citet{Drager2011} found that older speakers were more sensitive in their automatic compensation for ongoing phonetic changes, we find no such effect for the explicit reports on syntactic variables. For the changing variables, there is no significant effect of informant age on either the perceived `age' of the variants %~(TODO need to fit this model separately, this is not straightforwardly clear from Section~\ref{sec:oldervar})
or the perceived differences in apparent time~(Section~\ref{sec:apparenttime}).%, or on the estimates of how much `younger' and `older' speaker groups use the variants.

\subsection{Between-participant differences: gender}

The only significant effects of binary gender were found in the first two questions, i.e.~the reported `self' as well as `other speakers' usage levels: females tended to report \emph{higher} levels of the incoming variant both for themselves and the population as a whole. This tendency was present across all four sociolinguistic variables, whether changing or not.
The raw data of the responses split by variable and gender is shown in Figure~\ref{fig:genderreports}.

<<genderreports, fig.cap="Raw data for responses regarding self-usage by sociolinguistic variable and binary gender. For the changing variables, females generally report higher level usage of the incoming majority variants.">>=

# TODO do groups and make stacked?
groupedhistogram(~ self | longvar + gender, ylim=c(0, 90))

#groupedhistogram(~ other | longvar + gender, data=d)
#par(mfrow=c(2,1), mar=par("mar")-c(4,2,2,2))
#mosaicplot(table(d$var, d$gender, d$self), color=temp.colors(5), main="Reported self-usage")
#mosaicplot(table(d$var, d$gender, d$other), color=temp.colors(5), main="Reported population usage")
@

This gender effect does \emph{not} translate to a higher difference between perceived self-usage and perceived community usage, i.e.~females do \emph{not} perceive themselves to be further `ahead' the community than males do, the answers to both questions appear to be shifted in unison. Also, despite an often purported increased sensitivity to linguistic changes among females, neither the identification of the `older' variants~(Section~\ref{sec:oldervar}) nor the strength of the perceived apparent time differences~(Section~\ref{sec:apparenttime}) showed significant effects of participant gender.
%In relation to previous sociolinguistic research which has revealed gender differences where women were often found to be leading linguistic changes has been used to argue that, due to their social position, women are more sensitive to sociolinguistic cues~(Labov, inter alia).

%For the three changing variables pooled together, whether participants correctly report the outgoing variant to be older is not predicted well by any of the participant variables, in particular not by gender or age.

% SELFDIFF thoughts:
% intriguing fact about selfdiff: 50% of people report themselves as being ahead, under 10% as being behind
%counts <- table(subset(d, var!='neg')$selfdiff, factor(subset(d, var!='neg')$var))
%barplot(t(t(counts)/colSums(counts)), legend=rownames(counts), col=cm.colors(5))
% Apart from the effect of age, it is intriguing that very few individuals report themselves to be `behind' the curve for the question types, as opposed to the imperatives. This effect might be a matter of the measure used here: the imperatives, still very much a change in progress, allow for a wider range of putting yourself `relative' to the community usage (on either extreme). Maybe, instead of measuring the absolute difference between selected categories per individual, the relative difference should be measured relative to the distribution of community-level responses?


% people are also VERY consistent in their 'young' reports viz. the earlier 'other people' community average
%plot(party::ctree(young ~ other+loc+age+gender+firstvar+firstolder+condition+var, data=changing))
% the same isn't true for the older speakers, for which the variable remains the only significant predictor
%plot(party::ctree(old ~ other+loc+age+gender+firstvar+firstolder+condition+var, data=changing))
% ordered logistic models of this fail due to many empty cells in the 5x5 table...

% correctly identifying the outgoing variable is a good predictor for rating older speakers as *really* outdated
%plot(party::ctree(olddiff ~ oldervar+loc+age+gender+firstvar+firstolder+condition+var, changing))
% but younger speakers are actually mostly marked as level (could be a combination of ceiling+edge-avoidance??)
%plot(party::ctree(youngdiff ~ oldervar+loc+age+gender+firstvar+firstolder+condition+var, changing))

\section{Summary \& conclusion}

In this work, we presented a new methodology to assess and measure quantitatively whether people can report the direction of currently ongoing changes based on their awareness of the variable usage levels of categorical sociolinguistic variables.
Results from 77 speakers show that people are reliably capable of reporting
apparent time differences within their speech community, as well as provide evaluations of the age of the different linguistic variants that are compatible with the direction of the changes.
Complementing earlier experimental results on individual speakers' use of their implicit knowledge of continuous sound changes, we obtained quantitative evidence for the explicit awareness of changes in three related morphosyntactic variables which are only attested at very low frequencies in everyday speech.
Even though their low frequency means that we have no quantitative production data to compare to, the absolute usage levels reported by our informants reflect what is known about the relative progress of the three changes, indicating that naive individuals can learn about variable usage rates even from very limited data.
%which makes them hard to study quantitatively for linguists -- it means that individuals do not have that much data available to figure out the changes either, and still they seem to be able to do it pretty well!
While it is possible that explicit socio-indexical commentary on the variants could be underlying the shared knowledge about the direction of changes, the quantitative difference in responses between variables as well as the age-stratified distribution of self-usage assessments within variables
suggests that the degree of knowledge about the variants cannot be straightforwardly reduced to qualitative connotations of specific variants as being `older', `more dialectal' etc.

Connecting the present work to related approaches, I briefly discussed the continuum of methodologies that are based on eliciting explicit judgments on language and language use from laypeople.
Our extension of a simple and fast survey method originally employed by \citet{Labov1966} and \citet{Trudgill1972} falls on a spectrum somewhere between current quantitative methods employed in syntactic research and the qualitative approaches to variation pervasive in the study of language attitudes. Our work is best understood as a contribution to the re-emerging field of \emph{perceptual dialectology} dedicated to the study of naive language users' impression of language variation and change. This branch of research embraces the assumption that subjective evaluations, whether qualitative or quantitative, should not be discarded a priori but that they can complement and support evidence collected by other means in important ways.
In Section~\ref{sec:judgmentcorrelation} in particular we showed that subjective reports of relative quantitative usage correlate well with measures derived from grammatical acceptability judgments.
% We investigated how the estimated usage rates that we elicited from participants relate to the other quantitative measure of linguistic evaluation available to us, namely acceptability judgments.

%age vector stuff
In the context of this thesis, the present work represents an empirical contribution to the study of individuals' capacity to detect and monitor ongoing changes in their community.
%Unlike in the case of evolution by self-replication (such as genes/genomes in the traditional view of biological evolution), the fact that linguistic conventions are replicated by external entities (humans) means that they are inherently open to a different set of selection mechanisms than the ones typically associated with evolution.
As argued in Chapter~\ref{ch:review}, the \emph{metalinguistic awareness} of innovations and changes in the individual provides a rich source for social biases which could underlie selection mechanisms at play in language change, such as the momentum-based selection bias presented in the previous chapter.
%idea that the selection of linguistic innovations could be driven 
While we complemented and extended existing work to morphosyntactic, categorical variables of low frequency, the study of individuals' sociolinguistic knowledge is still a new topic that will require much further work, particularly in respect to innovations and changes.

%and some concluding remark about how important meta-linguistic knowledge can potentially be in driving change.

%Humans do not just make use of linguistic conventions, they are also \emph{aware} of their own (and others') usage of specific conventions, as well as how patterns of use differ across space and time. 
%One unique future of human languages is that they even allow one to make \emph{meta-linguistic commentary} on language use, i.e. natural language allows one to \emph{language} about language~\citep{DeBeule2014}.
