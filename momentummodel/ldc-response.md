---
title: "Momentum in language change: response to reviewers"
---
<!-- pandoc ldc-response.md -o ldc-response.pdf -->

Firstly, we would like to thank the reviewers for their insightful comments and justified criticisms. One of the main concerns raised by both reviewers was the complexity of the model (in terms of number of parameters), and whether both the general model design as well as the particular parameter combinations we investigated are in fact realistic. As a main consequence we have greatly expanded the section on the numerical results from our simulations, which highlight that the model exhibits robust regimes which are not particularly sensitive to small changes in the parameter settings. Please find our point-by-point responses to the reviewer's comments below. <!-- To counter these concerns -->

## Reviewer 1

> 1) The functional form of Eq. (6) is not properly justified.
>
> 1.1) Please whether the values of x_alpha and x_gamma appearing in m'(t) in Eq. (11) refer to the perceived frequency or to the agent's usage rate x. In the latter case, I see no reason why to include this term in the function f(y): it is not a function of y, it is a function of x and t and could be added directly to (5).

See our changes regarding the vector notation in 2.1 and 2.2.

> 1.2) If I understood it correctly, the motivation for the "momentum" argument is that it includes a dependence no only on y but also on how the change is progressing. In this case, why not include a function that explicitly takes into account y(t) and y(t-1), etc.? It is absolutely unclear why different parameters alpha should be used to account for such "momentum". The text around Eq. (2) does not help to understand this point. Maybe this is justified in some previous literature, in which case it is essential to motivate it here as well.

We have expanded section 2.1 (and particularly the accompanying Figure 2) to highlight the important role of the $\gamma$ parameter.

A behaviour very similar to the reviewer's suggested 1-point difference approach can be achieved by setting the short-term decay rate to its extreme at $\gamma=1$, which makes an agent posit a trend based on the last received data point $y(t)$ only (in particular the momentum bias would simply be based on the difference between that last data point and the agent's own usage rate, i.e. $m(t)\propto y(t) - x_\alpha(t)$). While analytically the behaviour of such an approach would certainly yield a similar dynamic to the bias as we investigate it, the 1-point difference would be much less robust in the case of numerical simulations, where the difference between two consecutive values $y(t-1), y(t)$ would mainly reflect the noise inherent in the model's probabilistic production. <!-- , which is sampled from the distribution $y(t)\sim Binomial(p=x(t), n=T)$. --> As we now indicate in the paper, the information extracted from this extremely short-term 1-point difference would consequently not be robust enough to reliably determine the direction in which the population-wide usage level is currently trending.

<!-- If I understand it correctly the reviewer's suggestion is to remove the need for the second learning rate $\gamma$ by having the momentum bias be based on the latest 1-point difference (i.e. the numerical approximation of the slope) of the input time series. While analytically the behaviour of such an approach would certainly yield a similar dynamic to the bias as we investigate it, the 1-point difference would be much less robust in the case of numerical simulations, where the difference between two consecutive values $y(t-1), y(t)$ would mainly reflect the noise inherent in the model's probabilistic production, which is sampled from the distribution $y(t)\sim Binomial(p=x(t), n=T)$. The information extracted from this simple 1-point difference would consequently not be robust enough to reliably determine the direction in which the population-wide usage level is currently trending. -->

<!-- Beyond these very extreme ranges (in the vicinity of $1$ as well as very close to the respective value of $\alpha$) the exact choice of $\gamma$ turns out not to be critical, at least when it comes to the shape of the trajectories (see below). -->

<!-- Basing the individuals' momentum biases on $y_t$ and $y_{t-1}$ directly would amount to extracting trends based on point-differences between individual samples, which are themselves incredibly noisy (basically samples from a Binomial with a resolution of $n=$T-parameter from the USM). The model with the two decay rates alpha and gamma is more general in that it can capture both strongly erratic trend behaviour of this sort by setting gamma to 1, in which case $x_gamma(t) = y_t$.
reviewer 1 asks whether it is really necessary to include an extra parameter (gamma) to calculate the momentum bias and suggests to have the 'perceived frequency' function f(.) simply depend on both y(t) and y(t-1) instead -->

> 1.3) The function f(y) defined in Eq. (6) has very awkward mathematical properties: it is discontinuous in y=0 and y=1, and positivity has to be imposed ad hoc. I don't see any justification for these properties so that I consider these to be a consequence of an ill proposed model. If these properties are not essential, or if linearity is obtained under some approximation, this should be clarified.
 
We have added a footnote explaining that the exact mathematical properties of the bias function $f(.)$ are indeed not essential: while $f(.)$ is defined over all of $[0,1]$, it is only ever evaluated at fractions of that interval depending on parameter $T$ (i.e. if we choose $T=4$ then it will only ever be evaluated at $0, 0.25, 0.5, 0.75, 1$). The exact shape and continuity of the function therefore matters much less than its monotonicity and the fact that $f(x)>x$ when the momentum term indicates an upwards-trend and that $f(x)<x$ when there is a downwards-trend.

<!-- 1.3 the discontinuity of the biasing function f(y) at y=0 and 1 is not exceptional in the context of other mathematical models of both cultural and biological evolution, as long as these are models of selection only, and therefore not allowing for mutation (or the introduction of new variants more generally). As noted in the text its form is based directly on the replicator selection formulation as used by Boyd & Richerson (1985), -->

> 2.1) In the first part of Sec. 2., the variable n receives three different sub-indices: "1,2.,3", "alpha", and "t_0". It is unclear thow to interpret the terms. For instance, if in Eq. (1) I consider the definition just above it ("n_t = ^n_alpha(t)), I obtain from Eq. (1) that n(t) =n(t-1).
> 2.2) Is it really necessary to introduce the vector notation in n? Is n_alpha one term of the vector? How is the "x" notation in Sec. 2.2 related to the "n" notation from the beginning of the section?

We have both removed the unmotivated usage of $t_0$ and clarified that we have merely omitted the $\hat{}$ in the sections discussing the USM for sake of simplicity. Our initial explanation of EWMAs using the vector notation for the time series and $\hat{}$ for the moving average over this time series was indeed inconsistent with the 'simplified' USM description we use in section 2.2 - the reason for this is that the vector notation, while useful to explain EWMAs in general, does not transfer well to the case where the moving average is not based directly on the input data time series $y$, but on the time series of 'biased' input data, $f(y)$.
<!-- Regarding reviewer 1's concerns over our mathematical notation we're afraid that there must have been some problems with the rendering of the math environments in the editorial manager's LaTeX build process. In particular it sounds as if the 'hat' over the time series vector variable that indicates that we are now talking about a time-dependent moving average \hat{n}(t) (based on the underlying time series \vec{n}=<n_1, n_2,...>) was not displayed in the reviewer's edition. -->

> 2.3) Caption of Fig. 2 (and also elsewhere). I don't understand what does it mean to "feed" an EWMA. Please write in mathematical form, also the x-y axis of the figure. Please clarify what the "linearly increasing factor" metnioned in the caption of Fig. 2. mean.

We have amended Figure 2 and provided additional clarifications in the figure caption.

> 3) In Sec. 4.1 the authors address the important question of how to select among different models of language change. The current model contains a large number of parameters which, if properly tuned, can lead to all sorts of s-shaped curves and rates of change. The selection of the relevant parameters and effects included in the different models requires more quantitative information about language change.

We have expanded the numerical simulation section and added Figure 4 (showing a large number of transitions across many parameter combinations) to highlight that, beyond dividing the parameter space into broad directed transition vs. neutral evolution regimes, the model is not highly sensitive to specific parameter settings (with the exception of the learning rate parameter $\alpha$ which would obviously alter the absolute rate of change).

<!-- In the present manuscript, the empirical information is only qualitative, e.g., the usage of "s-shaped curve". The decision whether a change is s shaped or not is simply not sufficient in order to select between most mathematical models. For instance, the curve shown in Fig. 1 seems to be perfectly symmetrical and exponential in both tails, the properties expected in simple dynamical systems models (see, e.g., the book "The computational Nature of Language Learning and Evolution"). Ref. J. R. Soc. Interface 11, 20141044 (2014) shows that curves of language change are often not like that and that further information can be obtained from the shape of S curves obtained in models and data. The alternative mentioned in the manuscript of tracking rates of change is notoriously difficult because it requires tracking also variants which never become popular.

We agree with the reviewer that it might very well be (quantitatively) impossible to distinguish between our momentum-based account and replicator selection accounts (whether those assuming functional or those assuming social selection pressures), particularly when many such pressures might be acting simultaneously (see also below in our response to reviewer 2). It is conceivable that this call might ultimately only be made on the soundness and grounds of motivating the accounts in theory, which is why we spend considerable time in the introduction+discussion to point out the assumptions and inconsistencies in replicator selection accounts. -->

> It is unclear to me at which times the external perturbations are added in the simulations, e.g, in Fig. 3.

We have amended Figure 3 and its caption to make both the timing and effect of the external perturbations more clear.

## Reviewer 2

> First, the authors identify several models of language change as well as two criteria for evaluating them, namely that a model has to account for both the sporadicity of change and its typical s-shaped trajectory. But there are problems with both these criteria. The authors claim that what they term language-internal accounts of change fail with respect to the first criterion they suggest, sporadicity; in particular, they over-predict change. But I don't think this claim is as clear or well-supported as the authors make it out to be. For example, the notion of functional load has gone in and out of philosophical favor over the past century and more, yet is a remarkably good predictor of phonological merger. Wedel et al. (2013) showed that two phonemes with fewer than twenty-six minimal pairs are overwhelmingly more likely to merge than two phonemes with more. Now, the number of minimal pairs, and hence the functional load, does not perfectly predict the occurrence of a merger, but it does quite well. Unless one insists upon identifying the necessary and sufficient conditions for a particular change, then this kind of language-internal account is actually pretty good, if imperfect. This is all that we can hope for from models that are undoubtedly wrong but useful to varying degrees.
>
> This gets at the fact that the actuation ''problem" is really a misnomer: The term implies that there exists a solution, that given enough detailed information we can somehow hammer out what distinguishes one case of change from another of stability. It seems more useful to think of actuation as a kind of epistemological limitation on the study of stochastic systems. We'll never actually have what Weinreich, Labov, and Herzog (1968) referred to as a strong theory of language change that ''would predict, from a description of a language state at some moment in time, the course of development which that language would undergo within a specified interval.'' (99--100) Unless the authors are willing to explain why actuation is a problem for language-internal accounts in detail, I think it would be best to note these kinds of accounts only in the concluding discussion. This would streamline things considerably.

We have amended the introductory sections to elaborate on this as well as pay more dues to the role of functional pressures. It was of course not our intention to discard or even play down the relevance of functional pressures, the issue we wanted to raise in the introduction section is whether functional factors evident in the individual can straightforwardly be translated into replication pressures which drive the ongoing selection of linguistic variants on the population level, overcoming the conformity pressures that guide much of language learning and use. The alternative option is that functional biases produce a skewed pool of baseline variation that otherwise arbitrary selection pressures then latch on to arbitrarily. This is the type of explanation implicit in both social accounts (cf. Ohala) and also how we see momentum-based selection in the bigger picture, which we hope to have made more clear in the current manuscript.

<!-- The reviewer's first criticism is that the criteria we propose to evaluate different accounts (sporadic changes and s-shaped trajectories) are not meaningful, particular as a means to distinguish replicator-neutral momentum-based selection vs. internal accounts that posit replicator selection based on functional pressures. -->

> The second criterion the authors put forward for a good model of change is the generation of an s-shaped curve as the proportion of the incoming variant increases over time. There are two problems with this. First the notion of being s-shaped is remarkably under-determined. At best, the notion of yielding an s-shaped curve is a qualitative criterion that holds of many models, and isn't particularly useful. For example, imagine two agents that choose between two variants according to individual rates. Both update their rate of usage given what their interlocutor said according to a simple linear learning rule. They will eventually converge on using one variant or the other. In fact, this holds for any size population. So, in principle, even this simple model could yield an s-shaped curve. Now, we might say that this kind of model is unlikely to yield an s-shaped curve, or that it isn't likely to yield such a curve under ''reasonable'' conditions. This is essentially the approach of Blythe and Croft (2012), where the parameters of the model are stipulated. But, it is not at all clear a priori that the parameters they stipulate are indeed reasonable. To find out we would need to fit the proposed models to data. This is a tall order, but needs to be done for us to take the utterance selection model seriously in the first place.

<!-- The second criterion that the reviewer contests are the directed, s-shaped trajectories, one particular point of concern being that even a pure neutral evolution model *can* exhibit s-shaped curves. -->In our expanded numerical analysis in section 3.3 we have now included a new graph displaying all trajectories produced by our simulations in the 'neutral evolution' condition (Figure 4), showing how the transitions produced by neutral evolution are of an inconsistent and qualitatively different type from those driven by momentum-based selection. The expanded analysis also shows that the reviewer's concerns regarding parameter tweaking are not as grave as suspected, instead producing consistent model behaviour across a wide range of parameter settings.

> It's also worth adding that do-support is not as good an example of it as the authors suggest. In Figure 1 there is a non-monotonic ''dip'' in the frequency of do-support across all contexts around 1600. (See Warner, 2005, and work by Aaron Ecay that provides a useful visualization of this dip: http://aaronecay.com/files/Ecay-DIGS16-Stylistc-effects-do-support.pdf) Even if they were to take into account the full range of evidence, it is not at all clear whether everyone can or would agree that a particular change is s-shaped or not. Simply put, it's a subjective qualitative visual criterion.

The updated manuscript acknowledges the often subjective nature of 's-shaped'-ness and gives a working definition based on previous literature. The influence of other factors is of course a general issue of 'competing pressures' in linguistic changes that no doubt exist. While we put forward a simplified new model of the selection of linguistic variants, we are perfectly aware that other (social) pressures are constantly acting on linguistic systems. We have expanded the introduction of the Discussion section to highlight the intricacies of such interacting pressures and pointed to current work aimed at detecting and disentangling the role of different pressures.

> On the assumption that the authors can make a compelling case for the utterance selection model, then we can evaluate the adoption of momentum into the model as a new neutral model of change. We can use the three criteria suggested by Blythe (2012) to evaluate whether the proposed neutral model is better than that of the replicator-neutral utterance selection model by itself. First, we want the proposed neutral model to be simple so that we can calculate probability over outcomes. Second, we want the free parameters of the proposed neutral model to be empirically falsifiable. Finally, we want interesting theoretical implications for rejecting the the neutral model. The authors need to demonstrate how the momentum model meets each of these criteria and is in some sense better or more explanatory than the utterance selection model (or, indeed, other alternatives).
> 
> With respect to the first criterion, the authors show the results for selected simulations of the model, but claim to have performed a wide range of simulations for various combinations of parameters, suggesting that the simulations are computationally reasonable and the first criterion for a neutral model is met.

Our expanded simulation results section provides more detailed evidence towards this point.

> Regarding the second criterion, I think that the momentum model has a steeper hill to climb. One of the main benefits of the traditional neutral models, at least in population genetics, is that the only parameters to be fit are the size of the population and the time scale. In comparison, the momentum model has six parameters as well as the time scale parameter. Some of these come for free x0, or could be informed by careful experimentations (cf. Gallistel et al. 2014). I have the sneaking suspicion that justifying particular parameters is going to be difficult, if not impossible. For example, there doesn't seem to be a way of testing the bias parameter b0 other than perhaps stipulating that b0 = 1. So, we can certainly fit the momentum model to data, but the resulting parameters are not necessarily going to be falsifiable, meaning the momentum model runs afoul of the second criterion.

As already mentioned above, our expanded numerical analysis section shows how the parameters are not prone to overfitting, with the parameter space being divided into few regimes within which the model exhibits very similar behaviour.

<!--The second big point raised by the reviewer is whether there are any good reasons to accept the replicator-neutral momentum-based selection model over the simpler 'pure' neutral evolution model. Similar to reviewer 1 there is concern over the momentum model's many parameters, which can make it difficult to justify the choice of particular parameter settings and combinations. Our expanded numerical analysis section shows how many of the parameters are not prone to abuse by overfitting, with the parameter space being divided into few regimes within which the model exhibits near-identical behaviour, in particular for the bias parameter 'b'.

Having more parameters the momentum-based selection model is indeed more general and subsumes the 'pure' neutral evolution model, and our revised manuscript includes more data on the (very rare) transitions that our simulations generate when we set $b=0$, which makes it identical to neutral evolution. The bias strength parameter $b$ does in fact only exhibit two regimes, the one near 0 where the bias is not strong enough to lead to a consistently self-reinforcing trend, and a regime where it is so reliably (in particular for $b\ge 1$). This insensitivity to the precise bias settings might be surprising to the reader, which is why **we have revised Figure 3, which shows the idealised production-perception loop behaviour of a single agent, to also indicate the 'perceived usage level' that a momentum-biased agent strives to align with**.-->

> The final criterion Blythe (2012) suggests for neutral models is that they make interesting  theoretical predictions. (Or, perhaps, put differently, that they indicate something interesting in those cases where we can reject them.) Here we come to the second main problem with this manuscript. The point is that we don't simply posit neutral models in isolation, but use them as the null hypothesis for testing alternative hypotheses. In this case, the most relevant alternative hypothesis is that a particular change is due to some kind of selection. So the authors need to address how selection would be incorporated into the model. More generally, they need to determine the conditions under which the null hypothesis can be rejected. However, my intuition (which could certainly be wrong) is that if we were to add selection to the model there would be two outcomes. Let's say we take the momentum model with selection as a generative model. For small amounts of selection, I suspect that the model would be indistinguishable from drift. That is, we wouldn't be able to distinguish the resulting trajectories from those that arise just from the neutral momentum model. Now, if we increase the selection a little bit, then it is going to interact with momentum and create a really strong feedback loop. Intuitively, this will yield trajectories that are more exponential than s-shaped (whatever that means). If we can't distinguish selection from drift for certain values, and we are only ever going to encounter those values, then adopting the momentum model as a neutral model is a bit self-defeating, since it can't ever tell us anything interesting about the underlying causes of change. This is intuition should be testable by simple biasing the sampling frequencies in the simulations by some small amount.
> In conclusion, this is an interesting approach to understanding the dynamics of language change, but needs to address significant problems. First, the authors need to show that the criteria they propose for accounts of language change are actually useful. Second, they need to show why the momentum model is an appropriate neutral model in comparison to other potential neutral models and actually offers theoretical insights within the broader methodological framework of null hypothesis testing.

The reviewer is right that, at least when it comes to the shape of individual trajectories, the dynamics of the momentum model will be near-indistinguishable from one where an asymmetric selection bias is applied. This is exactly the reason why our model is so relevant for theorising about linguistic change: where before a directed trajectory was automatically assumed to be evidence for an a-priori bias towards the incoming variant (be it functional or social, cf. Blythe & Croft 2012), our model shows that assuming an external bias is in fact *not* necessary to account for synchronised, directed changes across a community.

Related to the subjective nature of 's-shapedness' is the fact that the discriminative power of individual trajectories is generally very low: even neutral evolution *can* exhibit s-shaped trajectories, but it does so only very rarely. It is exactly for these reasons that we draw attention to the important role of the 'two rates of change' in the discussion section. While individual trajectories underspecify what kind of bias is driving the change, we argue that studying the relationship between individual changes and the likelihood of their actuation cross-linguistically might be the only adequate way to distinguish the predictions made by different accounts of change, and thereby get at the 'underlying causes of change', as suggested by reviewer.

<!-- With more parameters the momentum-based selection model is more general and in fact subsumes the 'pure' neutral evolution model, and our revised manuscript includes more data on the (very rare) transitions generated when we set $b=0$, which makes it identical to neutral evolution. We have also elaborated in the discussion section why the momentum-based selection model tells us something about the 'causes' of the changes: it provides an explanation of why the actuation of changes is underdetermined, namely because the bias emerges dynamically from the system.
-->
